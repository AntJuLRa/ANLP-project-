{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import os\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple definitions for file io\n",
    "def read_file(file_name):\n",
    "    file = unidecode.unidecode(open(file_name).read())\n",
    "    return file\n",
    "\n",
    "def read_csv(file_name, sep=','):\n",
    "    df = pd.read_csv(file_name, sep=sep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.kaggle.com/albertsuarez/azlyrics\n",
    "<h3>\n",
    "From this webpage, we download all 27 files to be processed and eventually used as dataset for classifier training.\n",
    "Some simple excel formatting is applied to achieve consistent dataframe shape when reading in the data\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The following block of code extracts, from the OHHLa.txt file, all rap songs titles and their respective artists and writes this information into artists_songs.txt file </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Resources/All lyrics OHHLa.txt', sep='\\n\\n\\n', engine='python',encoding='utf8', header = 0)\n",
    "songlist=[]\n",
    "artistlist = []\n",
    "print(data)\n",
    "linelist= data.iloc[:, 0]\n",
    "filter_a=[\"Artist:\"]\n",
    "filter_s=[\"Song:\"]\n",
    "\n",
    "#print(linelist[3])\n",
    "for k in range(len(linelist)):\n",
    "    if any(i in linelist[k] for i in filter_a):\n",
    "        a = linelist[k]\n",
    "        a = a.lstrip()\n",
    "        a = a.lower()\n",
    "        ind1 = a.find('artist:')\n",
    "        if ind1 != -1:\n",
    "            a = a[ind1+7:]\n",
    "        ind2 = a.find('f/')\n",
    "        if ind2 != -1:\n",
    "            a = a[0:ind2]\n",
    "        ind3 = a.find('(')\n",
    "        if ind3 != -1:\n",
    "            a = a[0:ind3]\n",
    "        a = a.replace(\" \", \"\")\n",
    "        a = a.replace(\"'\", \"\")\n",
    "        artistlist.append(a.lstrip().lower())\n",
    "        \n",
    "        for kk in range(k+1,k+4):\n",
    "            if any(j in linelist[kk] for j in filter_s):\n",
    "                s = linelist[kk]\n",
    "                s = s.lstrip()\n",
    "                s = s.lower()\n",
    "                ind4 = s.find('song:')\n",
    "                if ind4 != -1:\n",
    "                    s = s[ind4+5:]\n",
    "                ind5 = s.find('(')\n",
    "                if ind5 != -1:\n",
    "                    s = a[0:ind5]\n",
    "                s = s.replace(\" \", \"\")\n",
    "                s = s.replace(\"'\",\"\")\n",
    " \n",
    "                songlist.append([a,s])\n",
    "\n",
    "artistlist = sorted(set(artistlist))\n",
    "\n",
    "with open('Resources/artists_songs.txt', 'w') as f:\n",
    "    f.writelines(\"artist/song\\n\")\n",
    "    for item in songlist:\n",
    "        f.writelines(\"%s\\n\" % item)\n",
    "        \n",
    "with open('Resources/artists_names.txt', 'w') as f:\n",
    "    f.writelines(\"artist\\n\")\n",
    "    for item in artistlist:\n",
    "        f.writelines(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Given the OHHLA file containing 'all' rap songs, the following blocks are executed to filter out the rap songs in the azlyrics dataset.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the text file containing all the raps songs and their respective artists (from OHHLA),\n",
    "#read in the content\n",
    "raw = read_csv(\"Resources/artists_songs.txt\",'\\n')\n",
    "\n",
    "curr_arr = []\n",
    "artists_songs = []\n",
    "raprows = []\n",
    "\n",
    "for item in raw['artist/song'].values:\n",
    "    item = item.replace(\"'\",\"\")\n",
    "    artists_songs.append(item.strip(\"][\").split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet exclusively deals with the azlyrics file for artists whose alias/name starts with 0-9\n",
    "\n",
    "\"\"\"following snippet for initials 0-9\"\"\"\n",
    "\n",
    "file_root1 = 'Resources/azlyrics_lyrics_'\n",
    "file_format = '.csv'\n",
    "for item in artists_songs:\n",
    "    if item[0] == '':\n",
    "        continue\n",
    "    for ini in ['0','1','2','3','4','5','6','7','8','9']:\n",
    "        if item[0][0] == ini:\n",
    "            curr_arr.append(item)\n",
    "\n",
    "file_name = file_root1 + '19' + file_format\n",
    "file = read_csv(file_name)\n",
    "\n",
    "#if both artist's name and song matches, then add it to the rap list\n",
    "for item in curr_arr:\n",
    "    for index, row in file.iterrows():\n",
    "        if row['ARTIST_NAME'].lower().replace(\" \",\"\") == item[0] and row['SONG_NAME'].lower().replace(\" \",\"\") == item[1]:\n",
    "            raprows.append(row.values)\n",
    "            break\n",
    "\n",
    "\n",
    "rap_df = pd.DataFrame(raprows, columns=file.columns)   \n",
    "rap_df.to_csv (r'Resources/rap.csv', index = True, header=True)\n",
    "\"\"\"0-9 ends here\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet deals with the azlyrics files for artists whose alias/name starts with an alphabet\n",
    "\n",
    "\"\"\"all other alphabets start here\"\"\"\n",
    "initials = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\\\n",
    "                  'n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "for ini in initials:\n",
    "    print(\"currently processing: \", ini)\n",
    "    raprows = []\n",
    "    nraprows = []\n",
    "    curr_arr = []\n",
    "    \n",
    "    for item1 in artists_songs:\n",
    "        if item1[0] == '':\n",
    "            continue\n",
    "            \n",
    "        if item1[0][0] == ini:\n",
    "            curr_arr.append(item1)\n",
    "\n",
    "    file_name = file_root1 + ini + file_format\n",
    "    file = read_csv(file_name)\n",
    "\n",
    "    for item2 in curr_arr:\n",
    "        for index, row in file.iterrows():\n",
    "            if row['ARTIST_NAME'].lower().replace(\" \",\"\") == item2[0] and row['SONG_NAME'].lower().replace(\" \",\"\") == item2[1]:\n",
    "                raprows.append(row.values)\n",
    "                print(item2[1])\n",
    "                break\n",
    "                \n",
    "    rap_df = pd.DataFrame(raprows, columns=file.columns)   \n",
    "    rap_df.to_csv (r'Resources/rap.csv', index = True, mode='a', header=False)\n",
    "\"\"\"other alphabets end here\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The following blocks of code extract the non-rap songs and compile them into separate csv files.\n",
    "The criterion for non-rap songs is that the artist's name must not appear at all in the\n",
    "'artist_names.txt' file. Takes more than a few hours to execute completely.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet exclusively deals with the azlyrics file for artists whose alias/name starts with 0-9\n",
    "\n",
    "names = []\n",
    "raw = read_csv(\"Resources/artists_names.txt\",'\\n')\n",
    "for item in raw['artist'].values:\n",
    "    item = item.lstrip().replace(\"'\",\"\")\n",
    "    item = item.strip(\"][\").split(', ')[0][:item.find(',')]\n",
    "    names.append(item[:item.find('/')])\n",
    "    \n",
    "print(names)\n",
    "    \n",
    "\n",
    "file_root1 = 'Resources/azlyrics_lyrics_'\n",
    "file_format = '.csv'\n",
    "\n",
    "curr_names = []\n",
    "to_drop = []\n",
    "for item in names:\n",
    "    for ini in ['0','1','2','3','4','5','6','7','8','9']:\n",
    "        if (len(item)!= 0) and (item[0] == ini):\n",
    "            curr_names.append(item)\n",
    "\n",
    "file_name = file_root1 + '19' + file_format\n",
    "entries = read_csv(file_name)\n",
    "\n",
    "for item in curr_names:\n",
    "    for index, row in entries.iterrows():\n",
    "        if row['ARTIST_NAME'].lower().replace(\" \",\"\").replace(\",\",\"\") == item: \n",
    "            to_drop.append(index)\n",
    "            print(index, \"dropped\")\n",
    "             \n",
    "nrapdf = entries.drop(to_drop) \n",
    "nrapdf.to_csv (r'Resources/nrap.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet deals with the azlyrics files for artists whose alias/name starts with an alphabet\n",
    "\n",
    "for ini in initials:\n",
    "    curr_names = []\n",
    "    to_drop = []\n",
    "    print(\"currently processing: \", ini)\n",
    "    \n",
    "    for item in names:\n",
    "        if (len(item)!= 0) and (item[0] == ini):\n",
    "            curr_names.append(item)\n",
    "\n",
    "    file_name = file_root1 + ini + file_format\n",
    "    entries = read_csv(file_name)\n",
    "\n",
    "    for item in curr_names:\n",
    "        for index, row in entries.iterrows():\n",
    "            if row['ARTIST_NAME'].lower().replace(\" \",\"\").replace(\",\",\"\") == item: \n",
    "                to_drop.append(index)\n",
    "\n",
    "    nrapdf = entries.drop(to_drop) \n",
    "    nrapdf.to_csv (r'Dataset/AZlyrics/filtered/nrap.csv', index = False, mode='a',header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The csv file containing only rap song information is named rap.csv, the compiled list of non-rap song information is split into 3 separate csv files to reduce lag and the chances of crashing: nrap.csv, nrap2.csv,\n",
    "nrap3.csv. Some manual inspection is done to delete big chunks of foreign language songs, some will remain. </h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
