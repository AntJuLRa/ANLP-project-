{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import os\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple definitions for file io\n",
    "def read_file(file_name):\n",
    "    file = unidecode.unidecode(open(file_name).read())\n",
    "    return file\n",
    "\n",
    "def read_csv(file_name, sep=','):\n",
    "    df = pd.read_csv(file_name, sep=sep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.kaggle.com/albertsuarez/azlyrics\n",
    "<h3>\n",
    "from this webpage, we download all 27 files to be processed and eventually used as dataset for classifier training\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ohhla part here tbd\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Given the OHHLA file containing 'all' rap songs, the following blocks are executed to filter out the rap songs in the azlyrics dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the text file containing all the raps songs and their respective artists (from OHHLA),\n",
    "#read in the content\n",
    "with open('artists_songs.txt', 'r') as f:\n",
    "    raw = f.readlines()\n",
    "raw = read_csv(\"artists_songs.txt\",'\\n')\n",
    "\n",
    "names_sorted_arr = []\n",
    "curr_arr = []\n",
    "artists_songs = []\n",
    "raprows = []\n",
    "\n",
    "for item in raw['artist/song'].values:\n",
    "    item = item.replace(\"'\",\"\")\n",
    "    artists_songs.append(item.strip(\"][\").split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet exclusively deals with the azlyrics file for artists whose alias/name starts with 0-9\n",
    "\n",
    "\"\"\"following snippet for initials 0-9\"\"\"\n",
    "for item in artists_songs:\n",
    "    if item[0] == '':\n",
    "        continue\n",
    "    for ini in ['0','1','2','3','4','5','6','7','8','9']:\n",
    "        if item[0][0] == ini:\n",
    "            curr_arr.append(item)\n",
    "\n",
    "file_name = file_root1 + '19' + file_format\n",
    "file = read_csv(file_name)\n",
    "\n",
    "#if both artist's name and song matches, then add it to the rap list\n",
    "for item in curr_arr:\n",
    "    for index, row in file.iterrows():\n",
    "        if row['ARTIST_NAME'].lower().replace(\" \",\"\") == item[0] and row['SONG_NAME'].lower().replace(\" \",\"\") == item[1]:\n",
    "            raprows.append(row.values)\n",
    "            break\n",
    "\n",
    "\n",
    "rap_df = pd.DataFrame(raprows, columns=file.columns)   \n",
    "rap_df.to_csv (r'Dataset/AZlyrics/filtered/rap.csv', index = True, header=True)\n",
    "\"\"\"0-9 ends here\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet deals with the azlyrics files for artists whose alias/name starts with an alphabet\n",
    "\n",
    "\"\"\"all other alphabets start here\"\"\"\n",
    "initials = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\\\n",
    "                  'n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "for ini in initials:\n",
    "    print(\"currently processing: \", ini)\n",
    "    raprows = []\n",
    "    nraprows = []\n",
    "    curr_arr = []\n",
    "    \n",
    "    for item1 in artists_songs:\n",
    "        if item1[0] == '':\n",
    "            continue\n",
    "            \n",
    "        if item1[0][0] == ini:\n",
    "            curr_arr.append(item1)\n",
    "\n",
    "    file_name = file_root1 + ini + file_format\n",
    "    file = read_csv(file_name)\n",
    "\n",
    "    for item2 in curr_arr:\n",
    "        for index, row in file.iterrows():\n",
    "            if row['ARTIST_NAME'].lower().replace(\" \",\"\") == item2[0] and row['SONG_NAME'].lower().replace(\" \",\"\") == item2[1]:\n",
    "                raprows.append(row.values)\n",
    "                print(item2[1])\n",
    "                break\n",
    "                \n",
    "    rap_df = pd.DataFrame(raprows, columns=file.columns)   \n",
    "    rap_df.to_csv (r'Dataset/AZlyrics/filtered/rap.csv', index = True, mode='a', header=False)\n",
    "\"\"\"other alphabets end here\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The following blocks of code extract the non-rap songs and compile them into separate csv files.\n",
    "The criterion for non-rap songs is that the artist's name must not appear at all in the\n",
    "'artist_songs.txt' file used above for filtering out rap songs.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet exclusively deals with the azlyrics file for artists whose alias/name starts with 0-9\n",
    "\n",
    "names = []\n",
    "with open(\"Dataset/Rap Artists Names Cleaned.txt\") as file:\n",
    "    names = file.read().strip(\"][\").replace(\"'\",\"\").lower().split(', ')\n",
    "\n",
    "file_root1 = 'Dataset/AZlyrics/filtered/azlyrics_lyrics_'\n",
    "file_format = '.csv'\n",
    "\n",
    "curr_names = []\n",
    "to_drop = []\n",
    "for item in names:\n",
    "    for ini in ['0','1','2','3','4','5','6','7','8','9']:\n",
    "        if item[0] == ini:\n",
    "            curr_names.append(item)\n",
    "\n",
    "file_name = file_root1 + '19' + file_format\n",
    "entries = read_csv(file_name)\n",
    "\n",
    "for item in curr_names:\n",
    "    for index, row in entries.iterrows():\n",
    "        if row['ARTIST_NAME'].lower().replace(\" \",\"\").replace(\",\",\"\") == item: \n",
    "            to_drop.append(index)\n",
    "            print(index, \"dropped\")\n",
    "             \n",
    "nrapdf = entries.drop(to_drop) \n",
    "nrapdf.to_csv (r'Dataset/AZlyrics/filtered/nrap.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this snippet deals with the azlyrics files for artists whose alias/name starts with an alphabet\n",
    "\n",
    "for ini in initials:\n",
    "    curr_names = []\n",
    "    to_drop = []\n",
    "    print(\"currently processing: \", ini)\n",
    "    \n",
    "    for item in names:\n",
    "        if item[0] == ini:\n",
    "            curr_names.append(item)\n",
    "\n",
    "    file_name = file_root1 + ini + file_format\n",
    "    entries = read_csv(file_name)\n",
    "\n",
    "    for item in curr_names:\n",
    "        for index, row in entries.iterrows():\n",
    "            if row['ARTIST_NAME'].lower().replace(\" \",\"\").replace(\",\",\"\") == item: \n",
    "                to_drop.append(index)\n",
    "\n",
    "    nrapdf = entries.drop(to_drop) \n",
    "    nrapdf.to_csv (r'Dataset/AZlyrics/filtered/nrap.csv', index = False, mode='a',header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> The csv file containing only rap song information is named rap.csv, the compiled list of non-rap song information is split into 3 separate csv files to reduce lag and the chances of crashing: nrap.csv, nrap2.csv,\n",
    "nrap3.csv. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
