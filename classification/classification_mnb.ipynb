{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn as sk\n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import uniform\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"definitions of classifier and other functions, \n",
    "each call to the classifier function auto prints various metrics\"\"\"\n",
    "\n",
    "def read_csv(file_name, sep=','):\n",
    "    df = pd.read_csv(file_name, sep=sep)\n",
    "    return df\n",
    "\n",
    "def print_f1(Y_pred, Y_test):\n",
    "    print (f1_score(Y_test, Y_pred))\n",
    "\n",
    "def evaluate_model(Y_test,Y_pred):\n",
    "    TP = ((Y_pred == Y_test) & (Y_pred > 0)).sum() #true positives\n",
    "    TN = ((Y_pred == Y_test) & (Y_pred < 1)).sum() #true negatives\n",
    "    FP = ((Y_pred != Y_test) & (Y_pred > 0)).sum() #false positives\n",
    "    FN = ((Y_pred != Y_test) & (Y_pred < 1)).sum() #false negatives\n",
    "    \n",
    "    print(\"TP: \", TP)\n",
    "    print(\"TN: \", TN)\n",
    "    print(\"FP: \", FP)\n",
    "    print(\"FN: \", FN)\n",
    "    \n",
    "    f1 = sk.metrics.f1_score(Y_test, Y_pred)\n",
    "    print(\"f1 score is: \", f1)\n",
    "    \n",
    "\n",
    "def mnb_simple(X_train, Y_train, X_test, Y_test):\n",
    "    clf = MultinomialNB() #complement naive bayes classifier with different smoothing parameters\n",
    "\n",
    "    Y_pred = clf.fit(X_train, Y_train).predict(X_test) #fitting and predicting\n",
    "    f1 = sk.metrics.f1_score(Y_test, Y_pred)\n",
    "    print(\"f1 score is: \", f1)\n",
    "    \n",
    "    evaluate_model(Y_test,Y_pred)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def predict_from_proba(pred_proba, threshold):\n",
    "    lst = []\n",
    "    \n",
    "    for prob in pred_proba:\n",
    "        if prob[1] >= threshold:\n",
    "            lst.append(1)\n",
    "        else:\n",
    "            lst.append(0)        \n",
    "    return np.array(lst)\n",
    "\n",
    "def mismatched_indices(Y_test, Y_pred):\n",
    "    ind_list = []\n",
    "    for ind in range(len(Y_test)):\n",
    "        if Y_test[ind] != Y_pred[ind]:\n",
    "            ind_list.append(ind)\n",
    "    return ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_data = []\n",
    "\n",
    "rap_file = ['rap'] #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "nrap_files = ['nrap','nrap2','nrap3'] #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "file_root = '../resources/'#EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "file_format = '.csv' #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "\n",
    "rap_label_list = []\n",
    "nrap_label_list = []\n",
    "rap_lyrics_list = []\n",
    "nrap_lyrics_list = []\n",
    "all_lyrics_list = []\n",
    "\n",
    "\n",
    "#GET ALL LYRICS FROM RAP SONGS rap_lyrics_list, AND CREATE CORRESPONDING LABEL LIST rap_label_list\n",
    "for ini in rap_file:\n",
    "    file_name = file_root + ini + file_format \n",
    "    data = read_csv(file_name)\n",
    "    \n",
    "    all_lyrics_list = data['LYRICS'].values.tolist()\n",
    "    rap_lyrics_list = data['LYRICS'].values.tolist()\n",
    "    \n",
    "    for entry in rap_lyrics_list:\n",
    "        entry = entry.lower()\n",
    "        entry = re.sub(r'[^a-zA-Z0-9\\-\\']',' ',entry)\n",
    "        entry = re.sub(r'[\\s,.?]+',' ',entry)\n",
    "        rap_label_list.append(1)\n",
    "\n",
    "#GET ALL LYRICS FROM NON-RAP SONGS nrap_lyrics_list, AND CREATE CORRESPONDING LABEL LIST nrap_label_list\n",
    "for ini in nrap_files:\n",
    "    sublist = []\n",
    "    file_name = file_root + ini + file_format\n",
    "    data = read_csv(file_name)\n",
    "    \n",
    "    sublist = data['LYRICS'].values.tolist()\n",
    "    \n",
    "    for entry in sublist:\n",
    "        entry = entry.lower()\n",
    "        entry = re.sub(r'[^a-zA-Z0-9\\-\\']',' ',entry)\n",
    "        entry = re.sub(r'[\\s,.?]+',' ',entry)\n",
    "        nrap_label_list.append(0)\n",
    "        \n",
    "    all_lyrics_list = all_lyrics_list + sublist\n",
    "    nrap_lyrics_list = nrap_lyrics_list + sublist\n",
    "    \n",
    "#ALSO SAVES ALL LYRICS (RAP AND NON-RAP) INTO all_lyrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANUALLY FORCING THE TRAINING DATASET TO BE BALANCED\n",
    "x=4 #ADJUSTABLE STARTING ELEMENT, X MUST BE SMALLER THAN 30\n",
    "nrap_lyrics_list_sampled = nrap_lyrics_list[x::30]\n",
    "all_lyrics_list_sampled = rap_lyrics_list + nrap_lyrics_list_sampled\n",
    "label_list_sampled = rap_label_list + nrap_label_list[x::30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF VECTORIZER, PARAMETERS ADJUSTABLE, FITTED TO ONLY RAP LYRICS, VECTORIZED FOR \n",
    "tfidf_dictionary = TfidfVectorizer(ngram_range=(1,1),max_df=0.6,max_features=5000,min_df=0.00002, token_pattern=r\"[a-zA-Z0-9\\-\\']+\").fit(all_lyrics_list)\n",
    "lyrics_vectorized = tfidf_dictionary.transform(all_lyrics_list_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATASET FOR TRAINING AND TESTING, PARAMETERS ADJUSTABLE\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(lyrics_vectorized, label_list_sampled,\\\n",
    "                                                   test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00220033 0.99779967]\n",
      " [0.24172731 0.75827269]\n",
      " [0.48412026 0.51587974]\n",
      " ...\n",
      " [0.59294522 0.40705478]\n",
      " [0.90909443 0.09090557]\n",
      " [0.14283684 0.85716316]]\n"
     ]
    }
   ],
   "source": [
    "mnb_train = MultinomialNB()\n",
    "mnb_train.fit(X_train, Y_train)\n",
    "mnb_Y_pred_proba = mnb_train.predict_proba(X_test)\n",
    "print (mnb_Y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export classifer as pickled file\n",
    "\"\"\"following lines commented out as the output file already exist in the 'resources' folder\"\"\"\n",
    "#picklefile = '../resources/mnb_classifier.p'\n",
    "#with open(picklefile,'wb') as f:\n",
    "    #pickle.dump(mnb_train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export tfidf vectorizer as pickled file\n",
    "\"\"\"following lines commented out as the output file already exist in the 'resources' folder\"\"\"\n",
    "#picklefile = '../resources/tfidf_dict.p'\n",
    "#with open(picklefile,'wb') as f:\n",
    "    #pickle.dump(tfidf_dictionary,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(max_df=0.6, max_features=5000, min_df=2e-05,\n",
      "                token_pattern=\"[a-zA-Z0-9\\\\-\\\\']+\")\n"
     ]
    }
   ],
   "source": [
    "tf_load = pickle.load(open('../resources/tfidf_dict.p', 'rb'))\n",
    "print(tf_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
