{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn as sk\n",
    "import os\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import uniform\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://drive.google.com/drive/folders/1qD0tbXwpeD-cU8phT_w9-flJoj_0a-0s?usp=sharing\n",
    "\n",
    "GO TO THIS LINK, DOWNLOAD THE 4 CSV FILES AND UPLOAD THEM TO THE DIRECTORY SEEN ON THE LEFT SIDE\n",
    "CLICK THE ICON NAMED'FILES' AND CLICK UPLOAD ICON\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"definitions of different classifiers and other functions, \n",
    "each call to the classifier function auto prints various metrics\"\"\"\n",
    "\n",
    "def read_csv(file_name, sep=','):\n",
    "    df = pd.read_csv(file_name, sep=sep)\n",
    "    return df\n",
    "\n",
    "def print_f1(Y_pred, Y_test):\n",
    "    print (f1_score(Y_test, Y_pred))\n",
    "\n",
    "def evaluate_model(Y_test,Y_pred):\n",
    "    TP = ((Y_pred == Y_test) & (Y_pred > 0)).sum() #true positives\n",
    "    TN = ((Y_pred == Y_test) & (Y_pred < 1)).sum() #true negatives\n",
    "    FP = ((Y_pred != Y_test) & (Y_pred > 0)).sum() #false positives\n",
    "    FN = ((Y_pred != Y_test) & (Y_pred < 1)).sum() #false negatives\n",
    "    \n",
    "    print(\"TP: \", TP)\n",
    "    print(\"TN: \", TN)\n",
    "    print(\"FP: \", FP)\n",
    "    print(\"FN: \", FN)\n",
    "\n",
    "def cnb_simple(X_train, Y_train, X_test, Y_test):\n",
    "    clf = ComplementNB(alpha = 1)\n",
    "\n",
    "    Y_pred = clf.fit(X_train, Y_train).predict(X_test) #fitting and predicting\n",
    "    print(\"mean acc is: \", clf.score(X_test, Y_test))\n",
    "    f1 = sk.metrics.f1_score(Y_test, Y_pred)\n",
    "    print(\"f1 score is: \", f1)\n",
    "    \n",
    "    evaluate_model(Y_test,Y_pred)\n",
    "    return clf\n",
    "    \n",
    "def gnb_simple(X_train, Y_train, X_test, Y_test):\n",
    "    clf = GaussianNB() #complement naive bayes classifier with different smoothing parameters\n",
    "\n",
    "    Y_pred = clf.fit(X_train, Y_train).predict(X_test) #fitting and predicting\n",
    "    f1 = sk.metrics.f1_score(Y_test, Y_pred)\n",
    "    print(\"f1 score is: \", f1)\n",
    "    \n",
    "    evaluate_model(Y_test,Y_pred)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def mismatched_indices(Y_test, Y_pred):\n",
    "    ind_list = []\n",
    "    for ind in range(len(Y_test)):\n",
    "        if Y_test[ind] != Y_pred[ind]:\n",
    "            ind_list.append(ind)\n",
    "    return ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_data = []\n",
    "\n",
    "rap_file = ['rap'] #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "nrap_files = ['nrap','nrap2','nrap3'] #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "file_root = 'Dataset/AZlyrics/filtered/'#EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "file_format = '.csv' #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "\n",
    "rap_label_list = []\n",
    "nrap_label_list = []\n",
    "rap_lyrics_list = []\n",
    "nrap_lyrics_list = []\n",
    "all_lyrics_list = []\n",
    "\n",
    "\n",
    "#GET ALL LYRICS FROM RAP SONGS rap_lyrics_list, AND CREATE CORRESPONDING LABEL LIST rap_label_list\n",
    "for ini in rap_file:\n",
    "    file_name = ini + file_format \n",
    "    data = read_csv(file_name)\n",
    "    \n",
    "    all_lyrics_list = data['LYRICS'].values.tolist()\n",
    "    rap_lyrics_list = data['LYRICS'].values.tolist()\n",
    "    \n",
    "    for entry in rap_lyrics_list:\n",
    "        entry = entry.lower()\n",
    "        entry = re.sub(r'[^a-zA-Z0-9\\-\\']',' ',entry)\n",
    "        entry = re.sub(r'[\\s,.?]+',' ',entry)\n",
    "        rap_label_list.append(1)\n",
    "\n",
    "#GET ALL LYRICS FROM NON-RAP SONGS nrap_lyrics_list, AND CREATE CORRESPONDING LABEL LIST nrap_label_list\n",
    "for ini in nrap_files:\n",
    "    sublist = []\n",
    "    file_name = file_root + ini + file_format\n",
    "    data = read_csv(file_name)\n",
    "    \n",
    "    sublist = data['LYRICS'].values.tolist()\n",
    "    \n",
    "    for entry in sublist:\n",
    "        entry = entry.lower()\n",
    "        entry = re.sub(r'[^a-zA-Z0-9\\-\\']',' ',entry)\n",
    "        entry = re.sub(r'[\\s,.?]+',' ',entry)\n",
    "        nrap_label_list.append(0)\n",
    "        \n",
    "    all_lyrics_list = all_lyrics_list + sublist\n",
    "    nrap_lyrics_list = nrap_lyrics_list + sublist\n",
    "    \n",
    "#ALSO SAVES ALL LYRICS (RAP AND NON-RAP) INTO all_lyrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANUALLY FORCING THE TRAINING DATASET TO BE BALANCED\n",
    "x=4 #ADJUSTABLE STARTING ELEMENT, X MUST BE SMALLER THAN 30\n",
    "nrap_lyrics_list_sampled = nrap_lyrics_list[x::30]\n",
    "all_lyrics_list_sampled = rap_lyrics_list + nrap_lyrics_list_sampled\n",
    "label_list_sampled = rap_label_list + nrap_label_list[x::30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF VECTORIZER, PARAMETERS ADJUSTABLE, FITTED TO ONLY RAP LYRICS, VECTORIZED FOR \n",
    "tfidf_dictionary = TfidfVectorizer(ngram_range=(1,1),max_df=0.8,max_features=10000,min_df=0.00002, token_pattern=r\"[a-zA-Z0-9\\-\\']+\").fit(all_lyrics_list)\n",
    "lyrics_vectorized = tfidf_dictionary.transform(all_lyrics_list_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATASET FOR TRAINING AND TESTING, PARAMETERS ADJUSTABLE\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(lyrics_vectorized, label_list_sampled,\\\n",
    "                                                   test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is:  0.69097605893186\n",
      "TP:  938\n",
      "TN:  292\n",
      "FP:  742\n",
      "FN:  97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_simple(X_train.toarray(), Y_train, X_test.toarray(), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_file_list = ['Dataset/Generated/mc_list.p',\n",
    "                 'Dataset/Generated/onelyr_list.p',\n",
    "                 'Dataset/Generated/random_list.p',\n",
    "                 'Dataset/Generated/twolyr_list.p']\n",
    "\"\"\"\n",
    "\n",
    "test_file_list = ['mc_list.p',\n",
    "                 'onelyr_list.p',\n",
    "                 'random_list.p',\n",
    "                 'twolyr_list.p']\n",
    "\n",
    "\"\"\"Change the above list accordingly, each file should contain a list of songs/documents (a list of lists)\"\"\"\n",
    "\n",
    "collated_list = []\n",
    "\n",
    "for f in range(len(test_file_list)):    \n",
    "    pickle_file = open(test_file_list[f], \"rb\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            collated_list.append(pickle.load(pickle_file))\n",
    "        except EOFError:\n",
    "            break\n",
    "            \n",
    "mc = collated_list[0] \n",
    "onelyr = collated_list[1]\n",
    "random = collated_list[2]\n",
    "twolyr = collated_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepares the test set and labels\n",
    "\n",
    "test_list = twolyr \"\"\"Change this line to one of the names of the test lists: mc/onelyr...\"\"\"\n",
    "test_labels = []\n",
    "\n",
    "for entry in test_list:\n",
    "    test_labels.append(1)\n",
    "\n",
    "test_vectorized = tfidf_dictionary.transform(test_list)\n",
    "X_test = test_vectorized\n",
    "Y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf = gnb_simple(X_train.toarray(), Y_train, X_test.toarray(), Y_test)\n",
    "gnb_Y_pred = gnb_clf.predict(X_test.toarray())\n",
    "\n",
    "#prints out the lines which the classifier deems not rap\n",
    "wrong = mismatched_indices(Y_test, gnb_Y_pred)\n",
    "for ind in wrong:\n",
    "    print(ind)\n",
    "    print(random[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
