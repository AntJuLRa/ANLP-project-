{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn as sk\n",
    "import os\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import uniform\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "\n",
    "def read_csv(file_name, sep=','):\n",
    "    df = pd.read_csv(file_name, sep=sep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"definitions of different classifiers, each call to the classifier function auto prints various metrics\"\"\"\n",
    "def evaluate_model(Y_test,Y_pred):\n",
    "    TP = ((Y_pred == Y_test) & (Y_pred > 0)).sum() #true positives\n",
    "    TN = ((Y_pred == Y_test) & (Y_pred < 1)).sum() #true negatives\n",
    "    FP = ((Y_pred != Y_test) & (Y_pred > 0)).sum() #false positives\n",
    "    FN = ((Y_pred != Y_test) & (Y_pred < 1)).sum() #false negatives\n",
    "    \n",
    "    print(\"TP: \", TP)\n",
    "    print(\"TN: \", TN)\n",
    "    print(\"FP: \", FP)\n",
    "    print(\"FN: \", FN)\n",
    "\n",
    "def cnb_simple(X_train, Y_train, X_test, Y_test):\n",
    "    clf = ComplementNB(alpha = 1)\n",
    "\n",
    "    Y_pred = clf.fit(X_train, Y_train).predict(X_test) #fitting and predicting\n",
    "    print(\"mean acc is: \", clf.score(X_test, Y_test))\n",
    "    f1 = sk.metrics.f1_score(Y_test, Y_pred)\n",
    "    print(\"f1 score is: \", f1)\n",
    "    \n",
    "    evaluate_model(Y_test,Y_pred)\n",
    "\n",
    "    \n",
    "def lgr_simple(X_train, Y_train, X_test, Y_test):\n",
    "    clf = LogisticRegression(max_iter=100)\n",
    "\n",
    "    Y_pred = clf.fit(X_train, Y_train).predict(X_test) #fitting and predicting\n",
    "    print(\"mean acc is: \", clf.score(X_test, Y_test))\n",
    "    f1 = sk.metrics.f1_score(Y_test, Y_pred)\n",
    "    print(\"f1 score is: \", f1)\n",
    "    \n",
    "    evaluate_model(Y_test,Y_pred)\n",
    "    \n",
    "\n",
    "def svm_simple(X_train, Y_train, X_test, Y_test):\n",
    "    clf = svm.SVC(C=10)\n",
    "    Y_pred = clf.fit(X_train, Y_train).predict(X_test) #fitting and predicting\n",
    "    print(\"mean acc is: \", clf.score(X_test, Y_test))\n",
    "    f1 = sk.metrics.f1_score(Y_test, Y_pred)\n",
    "    print(\"f1 score is: \", f1)\n",
    "    \n",
    "    evaluate_model(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_data = []\n",
    "\n",
    "rap_file = ['rap'] #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "nrap_files = ['nrap','nrap2','nrap3'] #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "file_root = 'Dataset/AZlyrics/filtered/'#EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "file_format = '.csv' #EDIT THESE LINES ACCORDING TO THE DIRECTORY AND FILE NAMES\n",
    "\n",
    "rap_label_list = []\n",
    "nrap_label_list = []\n",
    "rap_lyrics_list = []\n",
    "nrap_lyrics_list = []\n",
    "all_lyrics_list = []\n",
    "\n",
    "\n",
    "#GET ALL LYRICS FROM RAP SONGS rap_lyrics_list, AND CREATE CORRESPONDING LABEL LIST rap_label_list\n",
    "for ini in rap_file:\n",
    "    file_name = file_root + ini + file_format \n",
    "    data = read_csv(file_name)\n",
    "    \n",
    "    all_lyrics_list = data['LYRICS'].values.tolist()\n",
    "    rap_lyrics_list = data['LYRICS'].values.tolist()\n",
    "    \n",
    "    for entry in rap_lyrics_list:\n",
    "        entry = entry.lower()\n",
    "        entry = re.sub(r'[^a-zA-Z0-9\\-\\']',' ',entry)\n",
    "        entry = re.sub(r'[\\s,.?]+',' ',entry)\n",
    "        rap_label_list.append(1)\n",
    "\n",
    "#GET ALL LYRICS FROM NON-RAP SONGS nrap_lyrics_list, AND CREATE CORRESPONDING LABEL LIST nrap_label_list\n",
    "for ini in nrap_files:\n",
    "    sublist = []\n",
    "    file_name = file_root + ini + file_format\n",
    "    data = read_csv(file_name)\n",
    "    \n",
    "    sublist = data['LYRICS'].values.tolist()\n",
    "    \n",
    "    for entry in sublist:\n",
    "        entry = entry.lower()\n",
    "        entry = re.sub(r'[^a-zA-Z0-9\\-\\']',' ',entry)\n",
    "        entry = re.sub(r'[\\s,.?]+',' ',entry)\n",
    "        nrap_label_list.append(0)\n",
    "        \n",
    "    all_lyrics_list = all_lyrics_list + sublist\n",
    "    nrap_lyrics_list = nrap_lyrics_list + sublist\n",
    "    \n",
    "#ALSO SAVES ALL LYRICS (RAP AND NON-RAP) INTO all_lyrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANUALLY FORCING THE TRAINING DATASET TO BE BALANCED\n",
    "x=0 #ADJUSTABLE STARTING ELEMENT, X MUST BE SMALLER THAN 30\n",
    "nrap_lyrics_list_sampled = nrap_lyrics_list[x::30]\n",
    "all_lyrics_list_sampled = rap_lyrics_list + nrap_lyrics_list_sampled\n",
    "label_list_sampled = rap_label_list + nrap_label_list[x::30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF VECTORIZER, PARAMETERS ADJUSTABLE, FITTED TO ONLY RAP LYRICS, VECTORIZED FOR \n",
    "tfidf_dictionary = TfidfVectorizer(ngram_range=(1,1),max_df=0.7,min_df=0.0005,token_pattern=r\"[a-zA-Z0-9\\-\\']+\").fit(rap_lyrics_list)\n",
    "lyrics_vectorized = tfidf_dictionary.transform(all_lyrics_list_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATASET FOR TRAINING AND TESTING, PARAMETERS ADJUSTABLE\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(lyrics_vectorized, label_list_sampled,\\\n",
    "                                                   test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_simple(X_train.toarray(), Y_train, X_test.toarray(), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_simple(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_simple(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"start of keras, execute this only if gpu present locally\"\"\"\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING NN\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=lyrics_vectorized.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=32,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTING AND EVALUATING\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred_classes = model.predict_classes(X_test)\n",
    "evaluate_model(Y_test, y_pred_classes[:,0])\n",
    "print_f1(Y_test, y_pred_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
