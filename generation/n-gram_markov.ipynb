{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntJuLRa/ANLP-project-/blob/dev/generation/n-gram_markov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMHrzjmyTbqe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk import ngrams\n",
        "import itertools\n",
        "import re\n",
        "import random\n",
        "import dill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw7mp68UTbrk"
      },
      "source": [
        "filename = 'n-gram_markov.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS9P8ZnnTbrs"
      },
      "source": [
        "dill.dump_session(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTIa-s6MTbr2"
      },
      "source": [
        "dill.load_session(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvWhM78sTbr8"
      },
      "source": [
        "**some dummy data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKwIfIrSTbsG"
      },
      "source": [
        "data = pd.read_csv('output.txt', sep='\\n\\n\\n', engine='python',encoding='utf8', header = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw2jxEA9TbsP",
        "outputId": "e8e5526c-7e0c-498c-c78c-96f9a51ebff5"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist: 40 Thevz f/ Malika</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Album:  Honor Amongst Thevz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Song:   All I Wanna Do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chorus: Malika, P.S.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All I wanna do is spend some time with you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>And all I wanna do is bump 'n grind with you.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Artist: 40 Thevz f/ Malika\n",
              "0                    Album:  Honor Amongst Thevz\n",
              "1                         Song:   All I Wanna Do\n",
              "2                           Chorus: Malika, P.S.\n",
              "3    All I wanna do is spend some time with you.\n",
              "4  And all I wanna do is bump 'n grind with you."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUzLWuFlTbsc"
      },
      "source": [
        "linelist= data[\"Artist: 40 Thevz f/ Malika\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKXm0qCyTbsi"
      },
      "source": [
        "lines = [x for x in linelist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6CXhVO9Tbso"
      },
      "source": [
        "lines = [x for x in lines if x[:5] != 'Album' and x[:6]!='Artist' and x[0]!='*' and x[:5]!='Typed']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2chq9F3mTbst"
      },
      "source": [
        "def replace_verse(x):\n",
        "    if x[:5]=='Verse' or x[:6]=='Chorus' or x[:5]=='Intro' or x[0]=='[':\n",
        "        return \"NXTVRSE\"\n",
        "    if x[:4]=='Song':\n",
        "        return \"NXTSNG\"\n",
        "    else: \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqMHhRhtTbs7"
      },
      "source": [
        "lines = [replace_verse(x) for x in lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi8HbM1CTbtA"
      },
      "source": [
        "mini_lines = [re.sub(\"[^A-Za-z0-9\\-\\ ]\", \"\", x.lower()) for x in lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIyri8SaTbtD"
      },
      "source": [
        "from nltk.tokenize.sonority_sequencing import SyllableTokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWPbW6-HTbtH"
      },
      "source": [
        "word_lines = [TreebankWordTokenizer().tokenize(x) for x in mini_lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DvHp8tQTbtM"
      },
      "source": [
        "syllable_lines = [[SyllableTokenizer().tokenize(x) for x in y] for y in word_lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X2wNWc9TbtP"
      },
      "source": [
        "letter_lines = [list(x) for x in mini_lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V4O8TRfTbtV"
      },
      "source": [
        "all_lines = [x for x in word_lines if len(x)>0]\n",
        "for y in all_lines:\n",
        "    if y[0]!='nxtsng' and y[0]!='nxtvrse':\n",
        "        y.append('endline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWS7zcKTTbtZ"
      },
      "source": [
        "dummy = all_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdwlluECTbtj"
      },
      "source": [
        "long_dummy = [x for y in dummy for x in y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DryjtqEkTbtm"
      },
      "source": [
        "size = len(long_dummy) \n",
        "idx_list = [idx + 1 for idx, val in enumerate(long_dummy) if val == 'nxtsng'] \n",
        "  \n",
        "  \n",
        "listlist = [long_dummy[i: j] for i, j in\n",
        "        zip([0] + idx_list, idx_list + \n",
        "        ([size] if idx_list[-1] != size else []))] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ib8TAJlTbtr"
      },
      "source": [
        "**Plain n-gram markov model for generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAwwoiXGTbtu"
      },
      "source": [
        "class ngram_markov_generator(object):\n",
        "    \n",
        "    def __init__(self, order,  end='nxtsng', endline='endline', meta_list=['nxtvrse','nxtsng']):\n",
        "        self.end = end\n",
        "        self.endline = endline\n",
        "        self.meta_list = meta_list\n",
        "        self.order =order\n",
        "        self.freq_dict = dict()\n",
        "        \n",
        "    def train(self, tknzd_txt_list):\n",
        "        for text in tknzd_txt_list:\n",
        "            grams = list(ngrams(text, self.order+1))\n",
        "            for gram in grams:\n",
        "                self.add_to_dict(gram)\n",
        "            \n",
        "    def add_to_dict(self, gram):\n",
        "        try:\n",
        "            self.freq_dict[gram[:-1]][gram[-1]]+=1\n",
        "        except KeyError:\n",
        "            self.freq_dict[gram[:-1]]= FreqDist([gram[-1]])\n",
        "    \n",
        "    def generate_text(self, start, max_len=20, temp=1):\n",
        "        key = start[-self.order:]\n",
        "        res_sent= start\n",
        "        \n",
        "        for _ in itertools.repeat(None, max_len):\n",
        "            \n",
        "            with_temp = {key: value**(1/temp) for key, value in self.freq_dict[tuple(key)].items()}\n",
        "            dist = nltk.DictionaryProbDist(with_temp,normalize=True)\n",
        "            \n",
        "            nextword = dist.generate()\n",
        "            res_sent.append(nextword)\n",
        "            \n",
        "            if nextword==self.end:\n",
        "                break\n",
        "                \n",
        "            key =res_sent[-self.order:]\n",
        "        \n",
        "        return res_sent\n",
        "    \n",
        "    def generate_lines(self, start, num_lines, max_len=200, temp=1):\n",
        "        key = start[-self.order:]\n",
        "        res_sent= start\n",
        "        linecount=0\n",
        "        for _ in itertools.repeat(None, max_len):\n",
        "            \n",
        "            with_temp = {key: value**(1/temp) for key, value in self.freq_dict[tuple(key)].items()}\n",
        "            dist = nltk.DictionaryProbDist(with_temp,normalize=True)\n",
        "            \n",
        "            nextword = dist.generate()\n",
        "            res_sent.append(nextword)\n",
        "            \n",
        "            if nextword==self.endline:\n",
        "                linecount = linecount + 1\n",
        "            \n",
        "            if linecount >= num_lines:\n",
        "                break\n",
        "            if nextword==self.end:\n",
        "                break\n",
        "                \n",
        "            key =res_sent[-self.order:]\n",
        "        \n",
        "        return res_sent\n",
        "\n",
        "    def nice_format(self, output_list):\n",
        "        no_meta = [x for x in output_list if x not in self.meta_list]\n",
        "        with_linebreaks = [\"\\n\" if x==self.endline else x for x in no_meta]\n",
        "        return \" \".join(with_linebreaks)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvZTt1n0Tbty"
      },
      "source": [
        "trigram_mc = ngram_markov_generator(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liS3WSGkTbt6"
      },
      "source": [
        "trigram_mc.train(listlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXGPg5U7Tbt9",
        "outputId": "42fe7742-33ff-4a62-ca6a-e37245cbe9d5"
      },
      "source": [
        "text= trigram_mc.generate_text(['nxtvrse','i','was','so'],max_len=20,temp=1)\n",
        "print(trigram_mc.nice_format(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i was so regular \n",
            " i appeared like a witch trapped in lying \n",
            " while youre looking through the first time show niggas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnqglCR6TbuC",
        "outputId": "343c030a-ca4d-4ea1-af2c-a035be318d10"
      },
      "source": [
        "lines= trigram_mc.generate_lines(['nxtvrse','i','was','so'],4)\n",
        "print(trigram_mc.nice_format(lines))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i was so beautiful from your front lawn \n",
            " everywhere we makin ya dance every dance got ta have it on your ass was to be in all of you bitches so vicious im still living \n",
            " who im not the past that comes from \n",
            " that you fell the pressure and pain take it from my golf swing \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFPYy4kWTbuH"
      },
      "source": [
        "**adding constraints**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgGbe8ZcTbuL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}