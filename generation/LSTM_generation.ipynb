{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AntJuLRa/ANLP-project-/blob/dev/generation/LSTM_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic3rHNkxNVuP"
   },
   "source": [
    "**Text generation with LSTM**  \n",
    "ANLP 2020/2021 final project  \n",
    "Friederike Schreiber, Peng Chen, Anton Rabe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5Ic0Mltqd-Cq"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dill\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fnc\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dT-DxLqPdfH8"
   },
   "outputs": [],
   "source": [
    "filename = '../resources/LSTM.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5dPkg_VpdyDe"
   },
   "outputs": [],
   "source": [
    "dill.dump_session(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOLSnmWidaE6"
   },
   "outputs": [],
   "source": [
    "dill.load_session(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYifAGUUOwBu"
   },
   "source": [
    "**Preparing the training data**  \n",
    "Because Hip Hop lyrics contain a lot of different spellings and unique words and the data set is also quite large we filter out less frequent words and buildour training data from all 4 line phrases that contain only words from our vocabulary.  \n",
    "This should help remove most unique samples and texts from languages other than english.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jTeoRIdmHD4K"
   },
   "outputs": [],
   "source": [
    "#loading the pickled data, a list of songs\n",
    "OHHLA_data = pickle.load(open( \"../resources/OHHLAdata_list.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ujr8tEogfNO"
   },
   "outputs": [],
   "source": [
    "flat_data = [word for song in OHHLA_data for word in song]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1lEAHZgkzDH"
   },
   "outputs": [],
   "source": [
    "#To reduce vocabulary size only include words that occur more than 30 times\n",
    "freq_dict= nltk.FreqDist(flat_data)\n",
    "valid_vocab= [word for word,freq in freq_dict.items() if freq>30]\n",
    "invalid_vocab= [word for word,freq in freq_dict.items() if freq<=30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLG8qoAQfoFw",
    "outputId": "39108522-5bd6-49c5-a2da-5e112f11e428"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10844"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZnx8lEMoxLf"
   },
   "outputs": [],
   "source": [
    "#setup an index dictonary for one hot encoding and provide a method to return adequate pytorch tensors\n",
    "index_dict = dict()\n",
    "for i, x in enumerate(valid_vocab):\n",
    "  index_dict[x]=i+1\n",
    "\n",
    "rev_index_dict = dict([reversed(i) for i in index_dict.items()])\n",
    "rev_index_dict[0]='UNK'\n",
    "\n",
    "def phrase_to_tensor(phrase, ind_dict):\n",
    "  word_list = [word for line in phrase for word in line]\n",
    "  tensor = torch.zeros(len(word_list)).long()\n",
    "  for i, x in enumerate(word_list):\n",
    "    try:\n",
    "      tensor[i]=ind_dict[x]\n",
    "    except KeyError:\n",
    "      tensor[i]=0\n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ2ovWwFjryD"
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "#We train on sequences of four lines\n",
    "verses = [list(x) for y in OHHLA_data for k, x in groupby(y, lambda x: x =='nxtvrse') if not k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJMjTX3cjHi3"
   },
   "outputs": [],
   "source": [
    "def get_phrases(verse,num_lines=4,endline='endline'):\n",
    "  lines = [list(x)+[endline] for k, x in groupby(verse, lambda x: x ==endline) if not k]\n",
    "  res=[]\n",
    "  for i,x in enumerate (lines[:len(lines)-num_lines+1]):\n",
    "    res.append(lines[i:i+num_lines])\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vo5Ib7zS-X2W"
   },
   "outputs": [],
   "source": [
    "#obtain a list of all possible four line phrases\n",
    "list_of_phrases=[get_phrases(verse) for verse in verses]\n",
    "phrases=[x for y in list_of_phrases for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIETCmYYFwdK"
   },
   "outputs": [],
   "source": [
    "#obtain all indeces of phrases that only include valid vocab\n",
    "invalid_phrases= []\n",
    "for i,phrase in enumerate(phrases):\n",
    "  for word in [word for line in phrase for word in line]:\n",
    "    if freq_dict[word]<=30:\n",
    "      invalid_phrases.append(i)\n",
    "      break\n",
    "\n",
    "valid_phrases = list(set(list(range(0,len(phrases)))) - set(invalid_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iKbRwyjq7Zk",
    "outputId": "fcf0136a-9856-4328-df4a-28f26ec6ac9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297440"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This leaves us with training data of ~300.000 phrases\n",
    "len(valid_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Sg44cyfK1hG"
   },
   "outputs": [],
   "source": [
    "#split phrases into random test and train set\n",
    "shuffled = random.sample(valid_phrases, len(valid_phrases))\n",
    "train_set= shuffled[:250000]\n",
    "test_set= shuffled[250000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iviZ9ZBitu_8"
   },
   "outputs": [],
   "source": [
    "#get random phrases/ random training samples for training\n",
    "def random_valid_phrase(index_list):\n",
    "  i= random.choice(index_list)\n",
    "  return phrases[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaJMSomO1y56"
   },
   "outputs": [],
   "source": [
    "def random_training_tensor(index_list):    \n",
    "    x=random_valid_phrase(index_list)\n",
    "    phrase = phrase_to_tensor(x,index_dict)\n",
    "    input = phrase[:-1]\n",
    "    target = phrase[1:]\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNoM3xmed-D6"
   },
   "source": [
    "**LSTM for text generation**  \n",
    "The basic model architecture is adopted from assignment 3.\n",
    "We set the standard embedding dimension to 100.\n",
    "For a large vocabulary values up to 300 are suggested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5cVhVlFd-EC"
   },
   "outputs": [],
   "source": [
    "#an adapted class for an LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, embedding_dim=100):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.i_dim= input_dim\n",
    "        self.e_dim= embedding_dim\n",
    "        self.h_dim= hidden_dim\n",
    "        self.o_dim= output_dim\n",
    "        self.n_layers= num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.i_dim, self.e_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.e_dim, hidden_size=self.h_dim, num_layers=self.n_layers)\n",
    "        self.out = nn.Linear(self.h_dim,self.o_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, inp, hidden_cell):\n",
    "        embedded = self.embedding(inp)\n",
    "        lstm_out, hidden = self.lstm(embedded.view(1,1,-1), hidden_cell)\n",
    "        res = self.out(lstm_out.view(1, -1))\n",
    "        res = fnc.log_softmax(res, dim=1)\n",
    "        \n",
    "        return res, hidden \n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden=torch.zeros(self.n_layers,1,self.h_dim)\n",
    "        cell = torch.zeros(self.n_layers,1,self.h_dim)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChYfKRC6KYev"
   },
   "outputs": [],
   "source": [
    "#a method for generating random sequences adapted from assignment 3.\n",
    "#The generation will stop after either the maximum number of words (max_len) or the required number of lines (num_lines) are reached.\n",
    "def generate(LSTM_model, start=['i'], max_len=150, num_lines=4, temp=0.8):\n",
    "    hidden, cell = LSTM_model.init_hidden()\n",
    "    prime_input = phrase_to_tensor([start], index_dict)\n",
    "    predicted = start[:]\n",
    "\n",
    "    for p in range(len(prime_input)):\n",
    "        _, (hidden, cell) = LSTM_model(prime_input[p], (hidden, cell)) \n",
    "    input = prime_input[-1]\n",
    "    \n",
    "    line_count=0\n",
    "    for p in range(max_len):\n",
    "        if line_count>=num_lines:\n",
    "          break\n",
    "\n",
    "        output, (hidden, cell) = LSTM_model(input, (hidden, cell))\n",
    "        \n",
    "        output_dist = output.data.view(-1).div(temp).exp()\n",
    "        i = int(torch.multinomial(output_dist, 1)[0]) \n",
    "        predicted_next = rev_index_dict[i]\n",
    "\n",
    "        if predicted_next=='endline':\n",
    "          line_count= line_count+1\n",
    "        \n",
    "        predicted.append(predicted_next)\n",
    "        input = phrase_to_tensor([[predicted_next]],index_dict)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIIIWR6AntKc"
   },
   "source": [
    "**Training**  \n",
    "Training models with different hidden layer size and one or two hidden layers. We are using Negative Log Likelihood loss together with log softmax in the final layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsTyR1A50X82"
   },
   "outputs": [],
   "source": [
    "#time tracking copied from assignment 3\n",
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omh1cVb50f8W"
   },
   "outputs": [],
   "source": [
    "#perform one training step on a given target and input and apply the optimization\n",
    "def training_step(LSTM_model, optimizer, input, target, sample_len, criterion):\n",
    "    hidden, cell = LSTM_model.init_hidden()\n",
    "    LSTM_model.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(sample_len):\n",
    "        output, (hidden, cell) = LSTM_model(input[c], (hidden, cell))\n",
    "        loss = loss + criterion(output, target[c].view(1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item() /sample_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7Y8AfIewtRC"
   },
   "outputs": [],
   "source": [
    "#train an LSTM model for n_epochs random training verses\n",
    "\n",
    "def train(model, optimizer, criterion, n_epochs,print_every, plot_every, index_list, return_loss_array):\n",
    "  loss_avg=0\n",
    "  all_losses=[]\n",
    "  start = time.time()\n",
    "  for epoch in range(1, n_epochs+1):\n",
    "    phrase = random_training_tensor(index_list)\n",
    "    #on very few occasions this throws an IndexError.\n",
    "    try:\n",
    "      loss = training_step(model, optimizer, phrase[0], phrase[1], len(phrase[1]), criterion)\n",
    "    except IndexError:\n",
    "      print(\"Error: \",phrase)\n",
    "    loss_avg += loss\n",
    "\n",
    "    # printing and documenting the loss during training adapted from assignment 3\n",
    "    if epoch % print_every == 0:\n",
    "        print('[{} ({} {}%) {:.4f}]'.format(time_since(start), epoch, epoch/n_epochs * 100, loss))\n",
    "        print(nice_format(generate(model)), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg/ plot_every)\n",
    "        loss_avg = 0\n",
    "    \n",
    "  if return_loss_array:\n",
    "    return all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkXn7TnW_4ms"
   },
   "outputs": [],
   "source": [
    "# convert list of words output to printable format\n",
    "def nice_format(output_list, meta_list=[]):\n",
    "        no_meta = [x for x in output_list if x not in meta_list]\n",
    "        with_linebreaks = [\"\\n\" if x=='endline' else x for x in no_meta]\n",
    "        return \" \".join(with_linebreaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTBEwGrXlIYG"
   },
   "outputs": [],
   "source": [
    "#A word level network with two hidden layers\n",
    "hidden_size = 128\n",
    "n_layers = 2\n",
    "loss_array = []\n",
    "n_items= len(index_dict)\n",
    "\n",
    "lr = 0.005\n",
    "twolayer_LSTM_model = LSTM(n_items, n_items, hidden_size, n_layers, embedding_dim=100)\n",
    "optimizer = torch.optim.Adam(twolayer_LSTM_model.parameters(), lr=lr)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXWTI2UOoNyD",
    "outputId": "acb07ec3-bb9f-4771-b156-f0a782fbdeaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5m 11s (1000 5.0%) 4.5836]\n",
      "i go to beg \n",
      " catch care of wallet \n",
      " i smoke you in my couch \n",
      " you know i 've been ridin ' on the passin ' eyes \n",
      " \n",
      "\n",
      "[10m 22s (2000 10.0%) 4.6040]\n",
      "i stay away \n",
      " you could go back \n",
      " i would do wo n't know i am the gang \n",
      " and you want it i'ma think there for real \n",
      " \n",
      "\n",
      "[15m 32s (3000 15.0%) 4.5529]\n",
      "i ca n't take a plane \n",
      " broken i am see i 'm ridin ' \n",
      " i cant get this game \n",
      " no less clocks with the sun more real \n",
      " \n",
      "\n",
      "[20m 40s (4000 20.0%) 5.5018]\n",
      "i go to you real time to down \n",
      " i often \n",
      " but a beast 'fore you get like \n",
      " i got nothing straight tryna pull up \n",
      " \n",
      "\n",
      "[25m 49s (5000 25.0%) 3.4650]\n",
      "i 'm like i need to do your name \n",
      " when you with else i earn the power i 'm slapped \n",
      " but i 'm as hell i 'm not a thug up \n",
      " it 's like a shame make a choice \n",
      " \n",
      "\n",
      "[31m 2s (6000 30.0%) 4.4782]\n",
      "i made that i can give a fuck \n",
      " you can not listen \n",
      " hold in my chest \n",
      " because i make a true day \n",
      " \n",
      "\n",
      "[36m 11s (7000 35.0%) 4.7560]\n",
      "i eat stage hard \n",
      " we do n't care the top \n",
      " go in the future \n",
      " why do you stop \n",
      " \n",
      "\n",
      "[41m 24s (8000 40.0%) 4.2493]\n",
      "i 'm talkin ' hop the shit \n",
      " then i 'm in the face with everybody \n",
      " but then the southside come up yeah \n",
      " i got bitch i 'm a the fuck i 'm a man we die \n",
      " \n",
      "\n",
      "[46m 37s (9000 45.0%) 4.6393]\n",
      "i was fuckin ' they beat ' it \n",
      " i 'm gone and you ready to get down \n",
      " i know you got a tree \n",
      " i 'm trying to break it away \n",
      " \n",
      "\n",
      "[51m 50s (10000 50.0%) 4.9526]\n",
      "i 'm on told you that you will \n",
      " i ai n't even even give it \n",
      " and i love the hoes straight for this \n",
      " i 'm in need me \n",
      " \n",
      "\n",
      "[57m 3s (11000 55.00000000000001%) 4.1957]\n",
      "i ai n't coming up your eyes \n",
      " where ya 's that do n't start to slow \n",
      " she ai n't got ta be in the chest two \n",
      " we know your whole hair \n",
      " \n",
      "\n",
      "[62m 13s (12000 60.0%) 4.3331]\n",
      "i 'm skate down \n",
      " i 'm just thats \n",
      " i 'm bout to pay the nigga and i 'm about love \n",
      " i do n't know you want the streets \n",
      " \n",
      "\n",
      "[67m 24s (13000 65.0%) 3.8057]\n",
      "i 'm back to the streets straight to the scene \n",
      " i 'm like a be that \n",
      " but you wan na understand \n",
      " and i 'm a teacher wan na ban \n",
      " \n",
      "\n",
      "[72m 38s (14000 70.0%) 3.9655]\n",
      "i 'm wrong \n",
      " i was what you 're for broken things \n",
      " i still admit you here \n",
      " i 'm a fuck you \n",
      " \n",
      "\n",
      "[77m 57s (15000 75.0%) 4.3230]\n",
      "i guess i wan na see me well that 's three but \n",
      " when it 's strong and it 's the heart \n",
      " it takes someone were less ' \n",
      " i ai n't got ta \n",
      " \n",
      "\n",
      "[83m 12s (16000 80.0%) 4.3512]\n",
      "i 'm 'bout to front \n",
      " when you crazy \n",
      " you got a bitch can run on till the casket \n",
      " i ai n't sinnin ' it 's deep \n",
      " \n",
      "\n",
      "[88m 30s (17000 85.0%) 4.8387]\n",
      "i 'm different of the best you \n",
      " i 'm real than i was the lies i 'm feelin ' it \n",
      " i would follow your hand get loose \n",
      " i ai n't even have the die \n",
      " \n",
      "\n",
      "[93m 48s (18000 90.0%) 4.8965]\n",
      "i hope to be her yes where they do n't \n",
      " uh you 're rockin ' on the dick \n",
      " like i come i feel like i 'm so far \n",
      " i taught you strong and on em up \n",
      " \n",
      "\n",
      "[99m 5s (19000 95.0%) 4.5344]\n",
      "i just know that i 'm still looking at my day \n",
      " i 'm just my father make that money nice \n",
      " i 'm the one i 'm not easy i 'm the back \n",
      " i ca n't even ca n't believe me i miss em the dopest chance to be \n",
      " \n",
      "\n",
      "[104m 23s (20000 100.0%) 5.7152]\n",
      "i know you hate to prove baby \n",
      " i 'm gon na figure you down to the play \n",
      " i 'm the rest of my last girl \n",
      " i 'm about to just \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_array = loss_array +train(twolayer_LSTM_model, optimizer, criterion, 20000, 1000, 10, train_set, return_loss_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOXvj7rwoOzy"
   },
   "outputs": [],
   "source": [
    "#pickle the object for further training sessions\n",
    "pickle.dump(twolayer_LSTM_model, open( \"../resources/2lyr_word_level_LSTM.p\", \"wb\" ))\n",
    "pickle.dump(loss_array, open( \"../resources/2lyr_losses.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYu_mtz5nobg"
   },
   "outputs": [],
   "source": [
    "#A word level network with one larger hidden layer\n",
    "hidden_size = 256\n",
    "n_layers = 1\n",
    "loss_array = []\n",
    "n_items= len(index_dict)\n",
    "\n",
    "lr = 0.005\n",
    "biglayer_LSTM_model = LSTM(n_items, n_items, hidden_size, n_layers, embedding_dim=100)\n",
    "optimizer = torch.optim.Adam(biglayer_LSTM_model.parameters(), lr=lr)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GMBy2R2UEub",
    "outputId": "dcaad8ef-f009-42e5-e11d-f96fada48669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7m 2s (1000 5.0%) 5.8368]\n",
      "i 'll can get this game of your life i 'm a benz \n",
      " they wo n't told me and playa are \n",
      " i want a high to the game of fact \n",
      " i 'm my past they do n't believe the shit \n",
      " \n",
      "\n",
      "[14m 5s (2000 10.0%) 4.7795]\n",
      "i said i 'm coming with your ass in the world \n",
      " i do n't care about me to your dick \n",
      " do n't know what i do you \n",
      " just about to god 's like the ice 's in the next \n",
      " \n",
      "\n",
      "[21m 11s (3000 15.0%) 4.9042]\n",
      "i do n't \n",
      " do what they say and if you kill the drippin ' \n",
      " you wan na find we wan na like me \n",
      " so when you like they ai n't no stack both 'll run in the top \n",
      " \n",
      "\n",
      "Error:  (tensor([    4,  3922,  4026,  1362,    67,  4153, 10844,   206, 10844,   206,\n",
      "        10844,   206,    14,    24,   972,     8,  6139,   545,    54,   704,\n",
      "        10844,   206, 10844,   206, 10844,   206,    14,    26,   277,    48,\n",
      "           89,  1245,   155,  5650, 10844,   206, 10844,   206, 10844,   206,\n",
      "           14,   616,  3280,  2591,    79,   998,    37,    24, 10844,   206,\n",
      "        10844,   206, 10844,   206]), tensor([ 3922,  4026,  1362,    67,  4153, 10844,   206, 10844,   206, 10844,\n",
      "          206,    14,    24,   972,     8,  6139,   545,    54,   704, 10844,\n",
      "          206, 10844,   206, 10844,   206,    14,    26,   277,    48,    89,\n",
      "         1245,   155,  5650, 10844,   206, 10844,   206, 10844,   206,    14,\n",
      "          616,  3280,  2591,    79,   998,    37,    24, 10844,   206, 10844,\n",
      "          206, 10844,   206,    14]))\n",
      "[28m 15s (4000 20.0%) 4.2429]\n",
      "i was know i need the raise \n",
      " i 'm feeling so mine \n",
      " then we do n't get rid of the cut nigga \n",
      " to go so baby you know the friends pop up \n",
      " \n",
      "\n",
      "Error:  (tensor([    4,    52,    24,  9708,   155,  5746,    14,     4,    61,   162,\n",
      "           36,   311,    12,    24, 10844,   225,    57,   276,     4,    52,\n",
      "           58,   261,    26,    14,     4,   459,    89,   833,    27,  1386,\n",
      "          144,    15,  1084,    26,    46,    38,  1217,    14,    24, 10026,\n",
      "         3838,    89,   550,    15,   576,    42,  1140]), tensor([   52,    24,  9708,   155,  5746,    14,     4,    61,   162,    36,\n",
      "          311,    12,    24, 10844,   225,    57,   276,     4,    52,    58,\n",
      "          261,    26,    14,     4,   459,    89,   833,    27,  1386,   144,\n",
      "           15,  1084,    26,    46,    38,  1217,    14,    24, 10026,  3838,\n",
      "           89,   550,    15,   576,    42,  1140,    14]))\n",
      "[35m 19s (5000 25.0%) 5.9330]\n",
      "i fuck \n",
      " we make sure i mean \n",
      " i hold me close \n",
      " get it bounce to blow my size \n",
      " \n",
      "\n",
      "[42m 40s (6000 30.0%) 3.9122]\n",
      "i fell \n",
      " just trying to find my own ya shall you have a real \n",
      " cause you leaving \n",
      " you get it twisted \n",
      " \n",
      "\n",
      "[49m 43s (7000 35.0%) 4.9874]\n",
      "i 've been on they \n",
      " i try to roll on \n",
      " gettin these niggas see work come \n",
      " to kick the wall \n",
      " \n",
      "\n",
      "[56m 41s (8000 40.0%) 6.1524]\n",
      "i do n't wan na see me she make that wan na be good \n",
      " tell me i 'm new \n",
      " take all that is way \n",
      " i 'm the first bitch only from me \n",
      " \n",
      "\n",
      "[63m 34s (9000 45.0%) 4.7279]\n",
      "i do n't got her a cat \n",
      " and dont they get it \n",
      " you gon na be the teeth know the muthafuckin like the dogs \n",
      " comin ' from a list \n",
      " \n",
      "\n",
      "Error:  (tensor([   74,     4,    21,  3526, 10844,    14,  2459,    38,  8148,  5219,\n",
      "         1299,   116,  1748,    74,     4,   130,    26,    14,   225,  2736,\n",
      "         2736,   225,    14,  1291,    89,   284,    23,    24,  4689,    63,\n",
      "         1053]), tensor([    4,    21,  3526, 10844,    14,  2459,    38,  8148,  5219,  1299,\n",
      "          116,  1748,    74,     4,   130,    26,    14,   225,  2736,  2736,\n",
      "          225,    14,  1291,    89,   284,    23,    24,  4689,    63,  1053,\n",
      "           14]))\n",
      "[70m 30s (10000 50.0%) 4.9572]\n",
      "i 'm got me \n",
      " i 'm in the game \n",
      " nigga just \n",
      " this is the only one \n",
      " \n",
      "\n",
      "[77m 31s (11000 55.00000000000001%) 4.0023]\n",
      "i 'm keep a minute \n",
      " you feel the regret \n",
      " still dream ' niggas the way i am with then when for it \n",
      " i 'm not fly shake this all my niggaz \n",
      " \n",
      "\n",
      "[84m 31s (12000 60.0%) 4.3838]\n",
      "i just got a cover of a running down \n",
      " i just was kind of knocked \n",
      " i get down with you \n",
      " i was coming at the hood show bill \n",
      " \n",
      "\n",
      "[91m 29s (13000 65.0%) 4.3224]\n",
      "i get you made me ! \n",
      " and that i 'm a fuck the shit \n",
      " what i want to know i need a cracked \n",
      " i said i made a gal the end \n",
      " \n",
      "\n",
      "[98m 28s (14000 70.0%) 5.6336]\n",
      "i 'm blowin ' with you \n",
      " for the headlights \n",
      " \n",
      " believe in the street \n",
      " \n",
      "\n",
      "[105m 22s (15000 75.0%) 4.4379]\n",
      "i 'm a hustle with things \n",
      " the fools in a moment and i 'm blessed \n",
      " got a queen try i could walk on \n",
      " i 'm clever not to work in the bottom \n",
      " \n",
      "\n",
      "[112m 18s (16000 80.0%) 7.0007]\n",
      "i just want to make the get to n't win i man \n",
      " and what 's a nigga \n",
      " say i remember of the taste up in your face baby \n",
      " if i 'm free he my whole world is to kill my advice \n",
      " \n",
      "\n",
      "[119m 10s (17000 85.0%) 5.1008]\n",
      "i do n't wan na keep it real \n",
      " i get 'em big pimpin ' in you \n",
      " fuck \n",
      " with you on your demand cause i will tell me what 's up \n",
      " \n",
      "\n",
      "[126m 17s (18000 90.0%) 4.9417]\n",
      "i walk through the club lookin ' the house for the bitch \n",
      " and i got ta make you live in what you get it \n",
      " 's the way you tell you be got to g \n",
      " water bad she was mine my body pay \n",
      " \n",
      "\n",
      "[133m 24s (19000 95.0%) 6.3105]\n",
      "i you do n't matter to do you put a my cash in your house \n",
      " i can get a little man and smoke me and lead me but you 're ridin out \n",
      " i get \n",
      " if i see you help me roll the hammer \n",
      " \n",
      "\n",
      "[140m 21s (20000 100.0%) 6.6222]\n",
      "i 'll see the same time you you dead \n",
      " i got ta chicago the wack \n",
      " c'mon \n",
      " do n't make you crazy but she got to pass me \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_array = loss_array +train(biglayer_LSTM_model, optimizer, criterion, 20000, 1000, 10, train_set, return_loss_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "do6pRWDzf1hV"
   },
   "outputs": [],
   "source": [
    "pickle.dump(biglayer_LSTM_model, open( \"../resources/biglyr_word_level_LSTM.p\", \"wb\" ))\n",
    "pickle.dump(loss_array, open( \"../resources/biglyr_losses.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENPU4JGOlOlU"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "Q1bHbS-IlTck",
    "outputId": "e0f8be0a-27b7-4505-a856-f3be98b58c2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbae28c1dd0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the training losses don't really go down because of the very big dataset\n",
    "plt.plot(loss_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9LXF3VloT19"
   },
   "source": [
    "**Try a smaller dataset and vocabulary**  \n",
    "The large dataset and large vocabulary leads to impratical training time and may contain differences that are to large for proper fitting.\n",
    "We decided to chose a higher treshold for our valid vocabulary.  This should lead to a smaller output layer and more cohesive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_ZL1UvVlZr6"
   },
   "outputs": [],
   "source": [
    "small_valid_vocab= [word for word,freq in freq_dict.items() if freq>150]\n",
    "big_invalid_vocab= [word for word,freq in freq_dict.items() if freq<=150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AinxJZJeGLJm",
    "outputId": "0820f3b5-f000-4c54-f33f-9835190e6062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_valid_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBFnl4qeGNPC"
   },
   "outputs": [],
   "source": [
    "invalid_phrases= []\n",
    "for i,phrase in enumerate(phrases):\n",
    "  for word in [word for line in phrase for word in line]:\n",
    "    if freq_dict[word]<=150:\n",
    "      invalid_phrases.append(i)\n",
    "      break\n",
    "\n",
    "valid_phrases = list(set(list(range(0,len(phrases)))) - set(invalid_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCw9X8nPGdhq"
   },
   "outputs": [],
   "source": [
    "index_dict = dict()\n",
    "for i, x in enumerate(small_valid_vocab):\n",
    "  index_dict[x]=i+1\n",
    "\n",
    "rev_index_dict = dict([reversed(i) for i in index_dict.items()])\n",
    "\n",
    "#split phrases into random test and train set\n",
    "shuffled = random.sample(valid_phrases, len(valid_phrases))\n",
    "train_set= shuffled[:50000]\n",
    "test_set= shuffled[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_0Hk-x3G8Yt"
   },
   "outputs": [],
   "source": [
    "#A word level network with one big layer trained on fewer samples with smaller vocabulary.\n",
    "hidden_size = 200\n",
    "n_layers = 2\n",
    "loss_array = []\n",
    "n_items= len(index_dict)\n",
    "\n",
    "lr = 0.005\n",
    "smallvocab2_LSTM_model = LSTM(n_items, n_items, hidden_size, n_layers, embedding_dim=100)\n",
    "optimizer = torch.optim.Adam(smallvocab2_LSTM_model.parameters(), lr=lr)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6YiDV1dIMxX",
    "outputId": "87e5cda4-a909-4bba-d15b-2d83f075bff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 10s (1000 2.0%) 5.3480]\n",
      "i want you \n",
      " they just do is that \n",
      " i just know i 'll wan like it \n",
      " and you love me \n",
      " \n",
      "\n",
      "[6m 19s (2000 4.0%) 5.7999]\n",
      "i just feel seem \n",
      " gave the sitting \n",
      " talk it \n",
      " the fo fame for nights and fuck you how he got ta dj the last \n",
      " \n",
      "\n",
      "[9m 28s (3000 6.0%) 3.6872]\n",
      "i do n't like you can could \n",
      " do n't give no make trapped niggaz if a place \n",
      " and i was off wan na take a \n",
      " and i ai n't see you \n",
      " \n",
      "\n",
      "[12m 39s (4000 8.0%) 4.2244]\n",
      "i feel what i do n't \n",
      " to the do it out \n",
      " you hear me but you came \n",
      " i know where the head for the morning \n",
      " \n",
      "\n",
      "Error:  (tensor([3628,    4,   60,  287,   15,    4,   75,   34,  443,  512,   14, 2592,\n",
      "          53,  139,   14,  167,   27,   62,   14,  376,    4,   60,  138,   24,\n",
      "        2448]), tensor([   4,   60,  287,   15,    4,   75,   34,  443,  512,   14, 2592,   53,\n",
      "         139,   14,  167,   27,   62,   14,  376,    4,   60,  138,   24, 2448,\n",
      "          14]))\n",
      "Error:  (tensor([ 322,   14, 3628,   14,  209,    4,  493,  494,  202,   24, 1754,   37,\n",
      "          38,  386,   13,  170,   14,    4,  170,  139,   56,  192]), tensor([  14, 3628,   14,  209,    4,  493,  494,  202,   24, 1754,   37,   38,\n",
      "         386,   13,  170,   14,    4,  170,  139,   56,  192,   14]))\n",
      "[15m 45s (5000 10.0%) 2.5332]\n",
      "i never got ta be stay \n",
      " bitches 're sorry take a lot of up \n",
      " by feel but you sing \n",
      " \n",
      " \n",
      "\n",
      "Error:  (tensor([  13,  105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,\n",
      "          20,   21,   49,   14, 1411,  362, 2706]), tensor([ 105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,   20,\n",
      "          21,   49,   14, 1411,  362, 2706,   14]))\n",
      "[18m 50s (6000 12.0%) 5.3935]\n",
      "i came your west out but bring a nigga man this ! \n",
      " ya do n't want me well \n",
      " but there 's a minute wrong with a mic and all up the notes i need it to explain \n",
      " i did n't never keep it \n",
      " \n",
      "\n",
      "[21m 57s (7000 14.000000000000002%) 3.8084]\n",
      "i 'm a gon na be down \n",
      " and i 'm like places and you do n't you be \n",
      " i can put my movie and he \n",
      " you can die \n",
      " \n",
      "\n",
      "Error:  (tensor([  24, 3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362,\n",
      "        2706,   14, 2191,   20,  443,   36,  175,  258]), tensor([3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362, 2706,\n",
      "          14, 2191,   20,  443,   36,  175,  258,   14]))\n",
      "[25m 4s (8000 16.0%) 4.1777]\n",
      "i 'll be like i do n't got ta ever show you tell me how i 'm fuckin ' \n",
      " i 'm on yo left you i swear to stay \n",
      " i 'm no more in the world \n",
      " so i do n't \n",
      " \n",
      "\n",
      "[28m 11s (9000 18.0%) 3.4007]\n",
      "i got that into the fuck of i 'm tellin ' yeah \n",
      " i got to joy my life \n",
      " get your night in and going i '' \n",
      " just quit like what they want \n",
      " \n",
      "\n",
      "Error:  (tensor([   4,   40,  111,    4,   60, 3628,   14,   13,  222,  170,   29,  223,\n",
      "         139, 1494,  276,   14,   56,   13,  480,  325,   14, 3073,  412,   36,\n",
      "         471]), tensor([  40,  111,    4,   60, 3628,   14,   13,  222,  170,   29,  223,  139,\n",
      "        1494,  276,   14,   56,   13,  480,  325,   14, 3073,  412,   36,  471,\n",
      "          14]))\n",
      "[31m 18s (10000 20.0%) 3.7932]\n",
      "i want that bitch \n",
      " when you call me \n",
      " i ca n't gon ' get this my friends \n",
      " i 'm takin on my deal \n",
      " \n",
      "\n",
      "Error:  (tensor([  15,    4,  165,   15,  258,   26,   27,  153,  387, 2472,   14,    4,\n",
      "          60,   24, 1053,  916,  479,   40,   42,  167,   13,  170,   14,    4,\n",
      "         800,   38,  435,  149,   24,  204,   15,    4,  110,  167,   26,   62,\n",
      "          14,  139,   27,  240,   92, 1997,   38, 1155,   42,  169,   42, 3628,\n",
      "          27,  116]), tensor([   4,  165,   15,  258,   26,   27,  153,  387, 2472,   14,    4,   60,\n",
      "          24, 1053,  916,  479,   40,   42,  167,   13,  170,   14,    4,  800,\n",
      "          38,  435,  149,   24,  204,   15,    4,  110,  167,   26,   62,   14,\n",
      "         139,   27,  240,   92, 1997,   38, 1155,   42,  169,   42, 3628,   27,\n",
      "         116,   14]))\n",
      "Error:  (tensor([3628,  949,   26,   70,  781,   13,  106,   36,  159,   42,   43,  114,\n",
      "        2513,  460,   53,   37,   24, 1585,  629,   14,    4,   60,   24,  156,\n",
      "          92,  100,  310, 1821,   92, 1220,   14,  110,  155,   26,  104, 1814,\n",
      "         147,    4,  169,   37,   92, 1792,   14,   15,    4,   60,   38,  848,\n",
      "         114,  326]), tensor([ 949,   26,   70,  781,   13,  106,   36,  159,   42,   43,  114, 2513,\n",
      "         460,   53,   37,   24, 1585,  629,   14,    4,   60,   24,  156,   92,\n",
      "         100,  310, 1821,   92, 1220,   14,  110,  155,   26,  104, 1814,  147,\n",
      "           4,  169,   37,   92, 1792,   14,   15,    4,   60,   38,  848,  114,\n",
      "         326,   14]))\n",
      "Error:  (tensor([   4,   40,  111,    4,   60, 3628,   14,   13,  222,  170,   29,  223,\n",
      "         139, 1494,  276,   14,   56,   13,  480,  325,   14, 3073,  412,   36,\n",
      "         471]), tensor([  40,  111,    4,   60, 3628,   14,   13,  222,  170,   29,  223,  139,\n",
      "        1494,  276,   14,   56,   13,  480,  325,   14, 3073,  412,   36,  471,\n",
      "          14]))\n",
      "[34m 27s (11000 22.0%) 4.0835]\n",
      "i done bring it nigga and i done stoppin to make it \n",
      " i got the kinda place \n",
      " i got ta catch you \n",
      " i 'm with you \n",
      " \n",
      "\n",
      "[37m 34s (12000 24.0%) 3.7944]\n",
      "i 'll spit the truth i 'm my past n't feel me \n",
      " i said i do n't understand the love and either this \n",
      " i 've been not from cars \n",
      " like it was really i do n't give a \n",
      " \n",
      "\n",
      "[40m 41s (13000 26.0%) 3.7626]\n",
      "i 'm doin my own with my heart a smile \n",
      " i said do you gon ' have stuck to you \n",
      " i can let you see this \n",
      " cause you blew the bed of the game \n",
      " \n",
      "\n",
      "[43m 51s (14000 28.000000000000004%) 4.2175]\n",
      "i keep you with you \n",
      " please do n't wan na get it out \n",
      " i would n't live you today i got to get here \n",
      " i just wan na be your best how i wan na know if it \n",
      " \n",
      "\n",
      "Error:  (tensor([1384, 1384, 1384, 1384, 1384,   14,   26,   27, 1641, 3628, 1544, 3467,\n",
      "          14,  322,   14,  227,   24,  498,  202]), tensor([1384, 1384, 1384, 1384,   14,   26,   27, 1641, 3628, 1544, 3467,   14,\n",
      "         322,   14,  227,   24,  498,  202,   14]))\n",
      "Error:  (tensor([3628,    4,   60,  287,   15,    4,   75,   34,  443,  512,   14, 2592,\n",
      "          53,  139,   14,  167,   27,   62,   14,  376,    4,   60,  138,   24,\n",
      "        2448]), tensor([   4,   60,  287,   15,    4,   75,   34,  443,  512,   14, 2592,   53,\n",
      "         139,   14,  167,   27,   62,   14,  376,    4,   60,  138,   24, 2448,\n",
      "          14]))\n",
      "[47m 4s (15000 30.0%) 3.1429]\n",
      "i got ta say \n",
      " i do n't let all you know \n",
      " i 've never 'm again i 'm funny i 'm saved on an rise i did n't wan na fuck out of the streets \n",
      " like young niggas lovin up and make me head \n",
      " \n",
      "\n",
      "[50m 19s (16000 32.0%) 5.2978]\n",
      "i 'd be not to be in \n",
      " and if i trust the sittin out \n",
      " it 's a dime forty \n",
      " caught it \n",
      " \n",
      "\n",
      "Error:  (tensor([ 302,   35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,\n",
      "          14,   24, 3628,  223,  144,   14,   70,   20,   21,   49]), tensor([  35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,   14,\n",
      "          24, 3628,  223,  144,   14,   70,   20,   21,   49,   14]))\n",
      "[53m 31s (17000 34.0%) 3.4894]\n",
      "i was more dick that weed from the wall \n",
      " ya always drop that \n",
      " we wan na get me up in my mouth \n",
      " make 'em fuck with the night \n",
      " \n",
      "\n",
      "Error:  (tensor([ 302,   35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,\n",
      "          14,   24, 3628,  223,  144,   14,   70,   20,   21,   49]), tensor([  35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,   14,\n",
      "          24, 3628,  223,  144,   14,   70,   20,   21,   49,   14]))\n",
      "Error:  (tensor([  13,  105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,\n",
      "          20,   21,   49,   14, 1411,  362, 2706]), tensor([ 105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,   20,\n",
      "          21,   49,   14, 1411,  362, 2706,   14]))\n",
      "Error:  (tensor([  20,   24, 1391,   20,   24,  321,  139,   13,  380,  326,   53,   31,\n",
      "          14,   98, 3628,  109,  209,   27,   72,   38, 2366,   15, 1335, 2216,\n",
      "        1355,  167,   27,   21,   26,   14,   26,   27,  299,   89,    4,  493,\n",
      "         110, 2739,   87,  209,   46,  848,   11,   14, 1071,  918,  139,  258,\n",
      "           4,  107,   42,   62,   15,  930,   46,   40,   38, 1260, 1489]), tensor([  24, 1391,   20,   24,  321,  139,   13,  380,  326,   53,   31,   14,\n",
      "          98, 3628,  109,  209,   27,   72,   38, 2366,   15, 1335, 2216, 1355,\n",
      "         167,   27,   21,   26,   14,   26,   27,  299,   89,    4,  493,  110,\n",
      "        2739,   87,  209,   46,  848,   11,   14, 1071,  918,  139,  258,    4,\n",
      "         107,   42,   62,   15,  930,   46,   40,   38, 1260, 1489,   14]))\n",
      "[56m 41s (18000 36.0%) 4.7641]\n",
      "i think you can see your ground \n",
      " now i like you \n",
      " you 're gon na stop ready a gangsta \n",
      " i ca n't be rest \n",
      " \n",
      "\n",
      "[59m 57s (19000 38.0%) 4.0867]\n",
      "i 've been gon ' come on \n",
      " taking the shit you life \n",
      " repeat \n",
      " you do n't need you for the big devil \n",
      " \n",
      "\n",
      "Error:  (tensor([ 258,  227,   24, 3172,  202,   14,  243,  139,   14,    4,   60, 1807,\n",
      "        1641, 3628,  315,   14,   13,  145,  474,  139,  578,  269]), tensor([ 227,   24, 3172,  202,   14,  243,  139,   14,    4,   60, 1807, 1641,\n",
      "        3628,  315,   14,   13,  145,  474,  139,  578,  269,   14]))\n",
      "[63m 11s (20000 40.0%) 3.5043]\n",
      "i 've never fear you can come ride \n",
      " i got you paper to man if you laid \n",
      " i got somethin \n",
      " i 'll get back for the sunshine the bills \n",
      " \n",
      "\n",
      "[66m 21s (21000 42.0%) 5.5905]\n",
      "i will be my money \n",
      " i wan na take your mouth \n",
      " i wan na know \n",
      " i guess i 'm taking her i 'm working \n",
      " \n",
      "\n",
      "[69m 33s (22000 44.0%) 4.3494]\n",
      "i want you like you like you come down and be smoking \n",
      " i just want to feel pain with me \n",
      " i wo n't take a player and pushing ya \n",
      " so i 'm just tryna be free \n",
      " \n",
      "\n",
      "[72m 48s (23000 46.0%) 3.7810]\n",
      "i do n't trust you made no not \n",
      " i need what 's up right \n",
      " i keep on to me \n",
      " you were the corner paint it \n",
      " \n",
      "\n",
      "Error:  (tensor([ 322,  585, 1641, 3628,   92,   68,   34,  462,   29,   14,   40,   68,\n",
      "          34,  775,   24,   40,   68,   34,  775,   24,   40,   68,   34,  775,\n",
      "          24, 2308,   14,    4,  108,   79,  725,   37,  109,  209,   79,  578,\n",
      "         725,   14,   40,   68,   34,  775,   24,   40,   68,   34,  775,   24,\n",
      "          40,   68,   34,  775,   24, 2308]), tensor([ 585, 1641, 3628,   92,   68,   34,  462,   29,   14,   40,   68,   34,\n",
      "         775,   24,   40,   68,   34,  775,   24,   40,   68,   34,  775,   24,\n",
      "        2308,   14,    4,  108,   79,  725,   37,  109,  209,   79,  578,  725,\n",
      "          14,   40,   68,   34,  775,   24,   40,   68,   34,  775,   24,   40,\n",
      "          68,   34,  775,   24, 2308,   14]))\n",
      "[76m 0s (24000 48.0%) 2.2738]\n",
      "i see you just to your click \n",
      " i never gon na see \n",
      " i had the time that \n",
      " i 've been waiting for free and \n",
      " \n",
      "\n",
      "Error:  (tensor([  24, 3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362,\n",
      "        2706,   14, 2191,   20,  443,   36,  175,  258]), tensor([3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362, 2706,\n",
      "          14, 2191,   20,  443,   36,  175,  258,   14]))\n",
      "[79m 18s (25000 50.0%) 4.1619]\n",
      "i had to hold you bitch girl tomorrow to man \n",
      " keep my bank of you \n",
      " it let me go to me to her baby \n",
      " cause there 's no time right here for \n",
      " \n",
      "\n",
      "Error:  (tensor([  24, 3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362,\n",
      "        2706,   14, 2191,   20,  443,   36,  175,  258]), tensor([3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362, 2706,\n",
      "          14, 2191,   20,  443,   36,  175,  258,   14]))\n",
      "[82m 35s (26000 52.0%) 5.1350]\n",
      "i said nigga \n",
      " hey i 'd do n't even know \n",
      " and you ai n't got ta lie \n",
      " you wan na ride on like i 'm still the bitch behind of \n",
      " \n",
      "\n",
      "[85m 52s (27000 54.0%) 3.2157]\n",
      "i 'm a make do n't trust it \n",
      " walk back away \n",
      " i 'm just a mine \n",
      " you know you like the way you say \n",
      " \n",
      "\n",
      "[89m 7s (28000 56.00000000000001%) 4.2290]\n",
      "i make the love \n",
      " you better \n",
      " i used my shit a know i hope it 's the ones \n",
      " i 'll say man \n",
      " \n",
      "\n",
      "Error:  (tensor([  98, 3628,  109,  209,   27,   72,   38, 2366,   15, 1335, 2216, 1355,\n",
      "         167,   27,   21,   26,   14,   26,   27,  299,   89,    4,  493,  110,\n",
      "        2739,   87,  209,   46,  848,   11,   14, 1071,  918,  139,  258,    4,\n",
      "         107,   42,   62,   15,  930,   46,   40,   38, 1260, 1489,   14,  243,\n",
      "          26,   27, 1898,   20,   24, 1635,  304,  258]), tensor([3628,  109,  209,   27,   72,   38, 2366,   15, 1335, 2216, 1355,  167,\n",
      "          27,   21,   26,   14,   26,   27,  299,   89,    4,  493,  110, 2739,\n",
      "          87,  209,   46,  848,   11,   14, 1071,  918,  139,  258,    4,  107,\n",
      "          42,   62,   15,  930,   46,   40,   38, 1260, 1489,   14,  243,   26,\n",
      "          27, 1898,   20,   24, 1635,  304,  258,   14]))\n",
      "[92m 25s (29000 57.99999999999999%) 5.0514]\n",
      "i used to be with a couple shit \n",
      " and you may get a real nigga \n",
      " it 's better than the money every chance to live what i 'm about \n",
      " and fed ya doors the track on the edge \n",
      " \n",
      "\n",
      "Error:  (tensor([  13,  145,   62,  414,  580,   87, 1720, 2247,    8,   24,  221,  156,\n",
      "           4,  435,   24,  752,   12,   26,   27,   70,  643, 3112, 2907,  899,\n",
      "          14, 1479,  651,    4,  493,  494,   70,  535,   14,   70, 1521,  695,\n",
      "           4,  493,  494, 2780,  304,  450,   24,   14, 3628,  949,   26,   70,\n",
      "         781,   13,  106,   36,  159,   42,   43,  114, 2513,  460,   53,   37,\n",
      "          24, 1585,  629]), tensor([ 145,   62,  414,  580,   87, 1720, 2247,    8,   24,  221,  156,    4,\n",
      "         435,   24,  752,   12,   26,   27,   70,  643, 3112, 2907,  899,   14,\n",
      "        1479,  651,    4,  493,  494,   70,  535,   14,   70, 1521,  695,    4,\n",
      "         493,  494, 2780,  304,  450,   24,   14, 3628,  949,   26,   70,  781,\n",
      "          13,  106,   36,  159,   42,   43,  114, 2513,  460,   53,   37,   24,\n",
      "        1585,  629,   14]))\n",
      "Error:  (tensor([1384, 1384, 1384, 1384, 1384,   14,   26,   27, 1641, 3628, 1544, 3467,\n",
      "          14,  322,   14,  227,   24,  498,  202]), tensor([1384, 1384, 1384, 1384,   14,   26,   27, 1641, 3628, 1544, 3467,   14,\n",
      "         322,   14,  227,   24,  498,  202,   14]))\n",
      "Error:  (tensor([ 302,   35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,\n",
      "          14,   24, 3628,  223,  144,   14,   70,   20,   21,   49]), tensor([  35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,   14,\n",
      "          24, 3628,  223,  144,   14,   70,   20,   21,   49,   14]))\n",
      "Error:  (tensor([ 139,    4,   51,   46,   87,  447,   23,    4,  433,   26,  464,   14,\n",
      "         911,  149,   24,  153,  608,   15, 1354,   14,  667,  433,   24, 2559,\n",
      "          14,   89,   13,  170,  139, 3628,   51,   26]), tensor([   4,   51,   46,   87,  447,   23,    4,  433,   26,  464,   14,  911,\n",
      "         149,   24,  153,  608,   15, 1354,   14,  667,  433,   24, 2559,   14,\n",
      "          89,   13,  170,  139, 3628,   51,   26,   14]))\n",
      "[95m 48s (30000 60.0%) 3.3020]\n",
      "i get some \n",
      " when the since you go around high \n",
      " you do n't know \n",
      " you ca n't make it fast \n",
      " \n",
      "\n",
      "Error:  (tensor([  13,  145,   62,  414,  580,   87, 1720, 2247,    8,   24,  221,  156,\n",
      "           4,  435,   24,  752,   12,   26,   27,   70,  643, 3112, 2907,  899,\n",
      "          14, 1479,  651,    4,  493,  494,   70,  535,   14,   70, 1521,  695,\n",
      "           4,  493,  494, 2780,  304,  450,   24,   14, 3628,  949,   26,   70,\n",
      "         781,   13,  106,   36,  159,   42,   43,  114, 2513,  460,   53,   37,\n",
      "          24, 1585,  629]), tensor([ 145,   62,  414,  580,   87, 1720, 2247,    8,   24,  221,  156,    4,\n",
      "         435,   24,  752,   12,   26,   27,   70,  643, 3112, 2907,  899,   14,\n",
      "        1479,  651,    4,  493,  494,   70,  535,   14,   70, 1521,  695,    4,\n",
      "         493,  494, 2780,  304,  450,   24,   14, 3628,  949,   26,   70,  781,\n",
      "          13,  106,   36,  159,   42,   43,  114, 2513,  460,   53,   37,   24,\n",
      "        1585,  629,   14]))\n",
      "Error:  (tensor([  70,  360,   30,   13,  480, 1439,  202,   29,    4,  426,   77, 1439,\n",
      "         202,   13,   14,    4,  170,   13,    7,   34,  105,   26,   14,   70,\n",
      "        1304,   66,   42, 3628,  223,    4,   60, 1642,   24,  204,   72,   92,\n",
      "         170,   29,   42,    7,   14,   70,   13,  145,  287,  149,   26]), tensor([ 360,   30,   13,  480, 1439,  202,   29,    4,  426,   77, 1439,  202,\n",
      "          13,   14,    4,  170,   13,    7,   34,  105,   26,   14,   70, 1304,\n",
      "          66,   42, 3628,  223,    4,   60, 1642,   24,  204,   72,   92,  170,\n",
      "          29,   42,    7,   14,   70,   13,  145,  287,  149,   26,   14]))\n",
      "Error:  (tensor([ 322,  585, 1641, 3628,   92,   68,   34,  462,   29,   14,   40,   68,\n",
      "          34,  775,   24,   40,   68,   34,  775,   24,   40,   68,   34,  775,\n",
      "          24, 2308,   14,    4,  108,   79,  725,   37,  109,  209,   79,  578,\n",
      "         725,   14,   40,   68,   34,  775,   24,   40,   68,   34,  775,   24,\n",
      "          40,   68,   34,  775,   24, 2308]), tensor([ 585, 1641, 3628,   92,   68,   34,  462,   29,   14,   40,   68,   34,\n",
      "         775,   24,   40,   68,   34,  775,   24,   40,   68,   34,  775,   24,\n",
      "        2308,   14,    4,  108,   79,  725,   37,  109,  209,   79,  578,  725,\n",
      "          14,   40,   68,   34,  775,   24,   40,   68,   34,  775,   24,   40,\n",
      "          68,   34,  775,   24, 2308,   14]))\n",
      "[99m 10s (31000 62.0%) 5.3064]\n",
      "i 'm just a ass on \n",
      " new shit \n",
      " and that 's for you one \n",
      " just tryna make that ass \n",
      " \n",
      "\n",
      "[102m 33s (32000 64.0%) 5.0481]\n",
      "i will see him i ca n't sleep \n",
      " nxtsng \n",
      " i got them girls \n",
      " to hate the low \n",
      " \n",
      "\n",
      "[106m 1s (33000 66.0%) 4.6331]\n",
      "i really wan na love you \n",
      " now i 'm workin ' and get your ass \n",
      " and the government but i 'm all my feet \n",
      " cause i 'm me on my mind while you 're just a do it \n",
      " \n",
      "\n",
      "[109m 24s (34000 68.0%) 4.4851]\n",
      "i let you get to it \n",
      " oh you 're shining good to the new \n",
      " got ta fuck ! \n",
      " singing i have my blow \n",
      " \n",
      "\n",
      "Error:  (tensor([  70, 1521,  695,    4,  493,  494, 2780,  304,  450,   24,   14, 3628,\n",
      "         949,   26,   70,  781,   13,  106,   36,  159,   42,   43,  114, 2513,\n",
      "         460,   53,   37,   24, 1585,  629,   14,    4,   60,   24,  156,   92,\n",
      "         100,  310, 1821,   92, 1220,   14,  110,  155,   26,  104, 1814,  147,\n",
      "           4,  169,   37,   92, 1792]), tensor([1521,  695,    4,  493,  494, 2780,  304,  450,   24,   14, 3628,  949,\n",
      "          26,   70,  781,   13,  106,   36,  159,   42,   43,  114, 2513,  460,\n",
      "          53,   37,   24, 1585,  629,   14,    4,   60,   24,  156,   92,  100,\n",
      "         310, 1821,   92, 1220,   14,  110,  155,   26,  104, 1814,  147,    4,\n",
      "         169,   37,   92, 1792,   14]))\n",
      "[112m 49s (35000 70.0%) 4.7276]\n",
      "i 'm gon na be there 's time what you see \n",
      " might get out of the streets \n",
      " cause forget a bell everywhere she 's going \n",
      " do what you do \n",
      " \n",
      "\n",
      "[116m 16s (36000 72.0%) 2.6381]\n",
      "i said i want it to the road \n",
      " yeah yeah \n",
      " i dont know \n",
      " ice and when a game \n",
      " \n",
      "\n",
      "Error:  (tensor([   4,  170,   13,    7,   34,  105,   26,   14,   70, 1304,   66,   42,\n",
      "        3628,  223,    4,   60, 1642,   24,  204,   72,   92,  170,   29,   42,\n",
      "           7,   14,   70,   13,  145,  287,  149,   26,   14,    1]), tensor([ 170,   13,    7,   34,  105,   26,   14,   70, 1304,   66,   42, 3628,\n",
      "         223,    4,   60, 1642,   24,  204,   72,   92,  170,   29,   42,    7,\n",
      "          14,   70,   13,  145,  287,  149,   26,   14,    1,   14]))\n",
      "Error:  (tensor([  13,  105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,\n",
      "          20,   21,   49,   14, 1411,  362, 2706]), tensor([ 105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,   20,\n",
      "          21,   49,   14, 1411,  362, 2706,   14]))\n",
      "[119m 51s (37000 74.0%) 3.7613]\n",
      "i be to no one other ' \n",
      " i ai n't going \n",
      " cause i 'm on clap \n",
      " dirty hoes \n",
      " \n",
      "\n",
      "Error:  (tensor([ 750,   27,  446,   36,  450,   87, 3318,   14, 3628,    8,   38, 2308,\n",
      "          14,   15,    4,    7,   87,  449,   14,    4,    7,   34,   96,  161,\n",
      "         617,  149,   13,  155]), tensor([  27,  446,   36,  450,   87, 3318,   14, 3628,    8,   38, 2308,   14,\n",
      "          15,    4,    7,   87,  449,   14,    4,    7,   34,   96,  161,  617,\n",
      "         149,   13,  155,   14]))\n",
      "[123m 26s (38000 76.0%) 6.8863]\n",
      "i i got ta go and you \n",
      " but she 's do n't make it like you know \n",
      " i 'm confused to go in a nigga \n",
      " i 'll do this \n",
      " \n",
      "\n",
      "[127m 5s (39000 78.0%) 3.8497]\n",
      "i want your money and it rock me out \n",
      " if i do n't know what the fuck \n",
      " back up in your blood real \n",
      " nigga a house here when he knew a family \n",
      " \n",
      "\n",
      "[130m 42s (40000 80.0%) 4.4681]\n",
      "i 've been the keys that 's the bed \n",
      " you aint not that i be working \n",
      " nigga baby girl \n",
      " i ai n't even scream \n",
      " \n",
      "\n",
      "Error:  (tensor([  13,  105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,\n",
      "          20,   21,   49,   14, 1411,  362, 2706]), tensor([ 105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,   20,\n",
      "          21,   49,   14, 1411,  362, 2706,   14]))\n",
      "Error:  (tensor([ 750,   27,  446,   36,  450,   87, 3318,   14, 3628,    8,   38, 2308,\n",
      "          14,   15,    4,    7,   87,  449,   14,    4,    7,   34,   96,  161,\n",
      "         617,  149,   13,  155]), tensor([  27,  446,   36,  450,   87, 3318,   14, 3628,    8,   38, 2308,   14,\n",
      "          15,    4,    7,   87,  449,   14,    4,    7,   34,   96,  161,  617,\n",
      "         149,   13,  155,   14]))\n",
      "[134m 20s (41000 82.0%) 4.5700]\n",
      "i got ta have do it \n",
      " i do n't really care you \n",
      " until the sun 's down you 're bad \n",
      " i just do that look do n't got what it do \n",
      " \n",
      "\n",
      "Error:  (tensor([  24, 3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362,\n",
      "        2706,   14, 2191,   20,  443,   36,  175,  258]), tensor([3628,  223,  144,   14,   70,   20,   21,   49,   14, 1411,  362, 2706,\n",
      "          14, 2191,   20,  443,   36,  175,  258,   14]))\n",
      "[138m 2s (42000 84.0%) 5.4474]\n",
      "i 'll take you you the way of me \n",
      " you 're like a long bitch \n",
      " dead steps lady \n",
      " they want me after me \n",
      " \n",
      "\n",
      "[141m 47s (43000 86.0%) 4.1448]\n",
      "i be fuckin ' i 'm never gon na get caught they know \n",
      " i know i 'm tryin ' to be the babe \n",
      " that 's a king of real \n",
      " it 's all and it 's the sky \n",
      " \n",
      "\n",
      "Error:  (tensor([  20,   24, 1391,   20,   24,  321,  139,   13,  380,  326,   53,   31,\n",
      "          14,   98, 3628,  109,  209,   27,   72,   38, 2366,   15, 1335, 2216,\n",
      "        1355,  167,   27,   21,   26,   14,   26,   27,  299,   89,    4,  493,\n",
      "         110, 2739,   87,  209,   46,  848,   11,   14, 1071,  918,  139,  258,\n",
      "           4,  107,   42,   62,   15,  930,   46,   40,   38, 1260, 1489]), tensor([  24, 1391,   20,   24,  321,  139,   13,  380,  326,   53,   31,   14,\n",
      "          98, 3628,  109,  209,   27,   72,   38, 2366,   15, 1335, 2216, 1355,\n",
      "         167,   27,   21,   26,   14,   26,   27,  299,   89,    4,  493,  110,\n",
      "        2739,   87,  209,   46,  848,   11,   14, 1071,  918,  139,  258,    4,\n",
      "         107,   42,   62,   15,  930,   46,   40,   38, 1260, 1489,   14]))\n",
      "[145m 36s (44000 88.0%) 4.0970]\n",
      "i 'm tired of be gon ' work to sleep i wo n't be \n",
      " i hit the bills takin be and my sister \n",
      " where the tears they preach without me \n",
      " it 's the struggle of me \n",
      " \n",
      "\n",
      "[149m 27s (45000 90.0%) 2.9519]\n",
      "i let you get through oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh \n",
      " i 'm just keep it real yeah but the mic is with it \n",
      " my go on my mind \n",
      " i got ta be no way \n",
      " \n",
      "\n",
      "Error:  (tensor([  13,  105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,\n",
      "          20,   21,   49,   14, 1411,  362, 2706]), tensor([ 105,   38,   71,   11,   14,   24, 3628,  223,  144,   14,   70,   20,\n",
      "          21,   49,   14, 1411,  362, 2706,   14]))\n",
      "[153m 18s (46000 92.0%) 4.2842]\n",
      "i i 'm just a stone with my heat \n",
      " i 'm dog \n",
      " i pray a good to it for you \n",
      " i 'm a motherfucker \n",
      " \n",
      "\n",
      "Error:  (tensor([ 302,   35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,\n",
      "          14,   24, 3628,  223,  144,   14,   70,   20,   21,   49]), tensor([  35,   36, 3030,  223,  497,   14,   13,  105,   38,   71,   11,   14,\n",
      "          24, 3628,  223,  144,   14,   70,   20,   21,   49,   14]))\n",
      "Error:  (tensor([ 319,  259,  633,   14,    4,   75,   34,  133,   51,   57,  224,  316,\n",
      "         240,   14,    4,   40,  111,    4,   60, 3628,   14,   13,  222,  170,\n",
      "          29,  223,  139, 1494,  276]), tensor([ 259,  633,   14,    4,   75,   34,  133,   51,   57,  224,  316,  240,\n",
      "          14,    4,   40,  111,    4,   60, 3628,   14,   13,  222,  170,   29,\n",
      "         223,  139, 1494,  276,   14]))\n",
      "[157m 12s (47000 94.0%) 2.9715]\n",
      "i i 'm selfish \n",
      " i 'm sorry than i like this \n",
      " can we keep it real \n",
      " well i 'll yell that \n",
      " \n",
      "\n",
      "[161m 10s (48000 96.0%) 4.3186]\n",
      "i pop your niggaz just hate that they do \n",
      " i 'm gon ' take you home \n",
      " i do n't want \n",
      " i 'll shoot the rhythm i say \n",
      " \n",
      "\n",
      "Error:  (tensor([ 513,   46,   24, 3193,   15,  161,  113,   14,   13,  232,  168,   29,\n",
      "          38,  740,   14,   56,  531,  561, 2705,   29, 1641, 3628,   14,  340,\n",
      "         976,  313]), tensor([  46,   24, 3193,   15,  161,  113,   14,   13,  232,  168,   29,   38,\n",
      "         740,   14,   56,  531,  561, 2705,   29, 1641, 3628,   14,  340,  976,\n",
      "         313,   14]))\n",
      "Error:  (tensor([  15,    4,   60, 2589,   36,   37, 1128,   14,  394,   15,  531,   19,\n",
      "         160,   14,   26,   27,   87,  558,   14,   70,    4,   60,   38,  116,\n",
      "         421,  944,  240, 3628,   27]), tensor([   4,   60, 2589,   36,   37, 1128,   14,  394,   15,  531,   19,  160,\n",
      "          14,   26,   27,   87,  558,   14,   70,    4,   60,   38,  116,  421,\n",
      "         944,  240, 3628,   27,   14]))\n",
      "[165m 10s (49000 98.0%) 5.3515]\n",
      "i like were your best job to tell you i did it \n",
      " do n't do is i do n't even know what i say \n",
      " so let my gold high \n",
      " why you 're all around \n",
      " \n",
      "\n",
      "Error:  (tensor([ 750,   27,  446,   36,  450,   87, 3318,   14, 3628,    8,   38, 2308,\n",
      "          14,   15,    4,    7,   87,  449,   14,    4,    7,   34,   96,  161,\n",
      "         617,  149,   13,  155]), tensor([  27,  446,   36,  450,   87, 3318,   14, 3628,    8,   38, 2308,   14,\n",
      "          15,    4,    7,   87,  449,   14,    4,    7,   34,   96,  161,  617,\n",
      "         149,   13,  155,   14]))\n",
      "[169m 13s (50000 100.0%) 4.8181]\n",
      "i 'm out \n",
      " i used to relax \n",
      " i just want my style \n",
      " i 'm going gon ' make you on \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_array = loss_array +train(smallvocab2_LSTM_model, optimizer, criterion, 50000, 1000, 10, train_set, return_loss_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhNhM0mGccBM"
   },
   "outputs": [],
   "source": [
    "pickle.dump(smallvocab2_LSTM_model,open(\"../resources/smallvocab2.p\",\"wb\"))\n",
    "pickle.dump(loss_array,open(\"../resources/smallvocabloss2.p\",\"wb\"))\n",
    "pickle.dump(shuffled,open(\"../resources/datasplit2.p\",\"wb\"))\n",
    "pickle.dump(optimizer,open(\"../resources/optimizer2.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ6fAg2rceQZ"
   },
   "source": [
    "**Generate from different models**\n",
    "Here we use different pickled models that we previously trained to generate lists of four line phrases that can be used as data for classification and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uW9igh1cjkB"
   },
   "outputs": [],
   "source": [
    "twolyr = pickle.load(open(\"../resources/2lyr_word_level_LSTM(2).p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXgMWS-TczyZ"
   },
   "outputs": [],
   "source": [
    "onelyr = pickle.load(open(\"../resources/biglyr_word_level_LSTM(1).p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzGBtFvlc5K5"
   },
   "outputs": [],
   "source": [
    "onlyr_list= []\n",
    "for x in range(100):\n",
    "  beginning= random_valid_phrase(valid_phrases)[0][0:1]\n",
    "  onlyr_list.append(nice_format(generate(onelyr, beginning)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sajQxoAhdUBs"
   },
   "outputs": [],
   "source": [
    "pickle.dump(onlyr_list, open(\"../resources/onelyr_list.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UEdkf0jdnrU"
   },
   "outputs": [],
   "source": [
    "twolyr_list= []\n",
    "for x in range(100):\n",
    "  beginning= random_valid_phrase(valid_phrases)[0][0:1]\n",
    "  twolyr_list.append(nice_format(generate(twolyr, beginning)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVg3-wOSeQ42"
   },
   "outputs": [],
   "source": [
    "pickle.dump(twolyr_list, open(\"../resources/twolyr_list.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "palyix2oelyW"
   },
   "outputs": [],
   "source": [
    "#generate a list of 100 random outputs for evaluation.\n",
    "random_list= []\n",
    "dist = nltk.DictionaryProbDist(freq_dict,normalize=True)\n",
    "for x in range(100):\n",
    "  length= random.choice(range(40,100))\n",
    "  output= []\n",
    "  for y in range(length):\n",
    "    output.append(dist.generate())\n",
    "  random_list.append(nice_format(output, ['nxstsng','nxtvrse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORKBrGP1fJPB"
   },
   "outputs": [],
   "source": [
    "pickle.dump(random_list, open(\"../resources/random_list.p\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LSTM generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
