{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntJuLRa/ANLP-project-/blob/dev/generation/LSTM_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ic0Mltqd-Cq"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import nltk\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fnc\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTeoRIdmHD4K"
      },
      "source": [
        "OHHLA_data = pickle.load(open( \"OHHLAdata_list.p\", \"rb\" ))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ujr8tEogfNO"
      },
      "source": [
        "flat_data = [word for song in OHHLA_data for word in song]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1lEAHZgkzDH"
      },
      "source": [
        "freq_dict= nltk.FreqDist(flat_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxY_38Rzo3SH"
      },
      "source": [
        "valid_vocab= [word for word,freq in freq_dict.items() if freq>30]\r\n",
        "invalid_vocab= [word for word,freq in freq_dict.items() if freq<=30]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLG8qoAQfoFw",
        "outputId": "1cd47510-6f17-4c93-e245-5bfbf102387b"
      },
      "source": [
        "len(valid_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZnx8lEMoxLf"
      },
      "source": [
        "index_dict = dict()\r\n",
        "for i, x in enumerate(valid_vocab):\r\n",
        "  index_dict[x]=i+1\r\n",
        "\r\n",
        "rev_index_dict = dict([reversed(i) for i in index_dict.items()])\r\n",
        "\r\n",
        "def phrase_to_tensor(phrase, ind_dict):\r\n",
        "  word_list = [word for line in phrase for word in line]\r\n",
        "  tensor = torch.zeros(len(word_list)).long()\r\n",
        "  for i, x in enumerate(word_list):\r\n",
        "    try:\r\n",
        "      tensor[i]=ind_dict[x]\r\n",
        "    except KeyError:\r\n",
        "      tensor[i]=0\r\n",
        "  return tensor"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ2ovWwFjryD"
      },
      "source": [
        "from itertools import groupby\r\n",
        "#We train on sequences of four lines\r\n",
        "verses = [list(x) for y in OHHLA_data for k, x in groupby(y, lambda x: x =='nxtvrse') if not k]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJMjTX3cjHi3"
      },
      "source": [
        "def get_phrases(verse,num_lines=4,endline='endline'):\r\n",
        "  lines = [list(x)+[endline] for k, x in groupby(verse, lambda x: x ==endline) if not k]\r\n",
        "  res=[]\r\n",
        "  for i,x in enumerate (lines[:len(lines)-num_lines+1]):\r\n",
        "    res.append(lines[i:i+num_lines])\r\n",
        "  return res"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo5Ib7zS-X2W"
      },
      "source": [
        "list_of_phrases=[get_phrases(verse) for verse in verses]\r\n",
        "phrases=[x for y in list_of_phrases for x in y]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIETCmYYFwdK"
      },
      "source": [
        "invalid_phrases= []\r\n",
        "for i,phrase in enumerate(phrases):\r\n",
        "  for word in [word for line in phrase for word in line]:\r\n",
        "    if freq_dict[word]<=30:\r\n",
        "      invalid_phrases.append(i)\r\n",
        "      break"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iKbRwyjq7Zk"
      },
      "source": [
        "valid_phrases = list(set(list(range(0,len(phrases)))) - set(invalid_phrases))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sg44cyfK1hG"
      },
      "source": [
        "shuffled = random.sample(valid_phrases, len(valid_phrases))\r\n",
        "train_set= shuffled[:25000]\r\n",
        "test_set= shuffled[25000:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iviZ9ZBitu_8"
      },
      "source": [
        "def random_valid_phrase(index_list):\r\n",
        "  i= random.choice(index_list)\r\n",
        "  return phrases[i]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaJMSomO1y56"
      },
      "source": [
        "def random_training_tensor(index_list):    \r\n",
        "    x=random_valid_phrase(index_list)\r\n",
        "    phrase = phrase_to_tensor(x,index_dict)\r\n",
        "    input = phrase[:-1]\r\n",
        "    target = phrase[1:]\r\n",
        "    return input, target"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNoM3xmed-D6"
      },
      "source": [
        "**LSTM for text generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5cVhVlFd-EC"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, embedding_dim=100):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.i_dim= input_dim\n",
        "        self.e_dim= embedding_dim\n",
        "        self.h_dim= hidden_dim\n",
        "        self.o_dim= output_dim\n",
        "        self.n_layers= num_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.i_dim, self.e_dim)\n",
        "        self.lstm = nn.LSTM(input_size=self.e_dim, hidden_size=self.h_dim, num_layers=self.n_layers)\n",
        "        self.out = nn.Linear(self.h_dim,self.o_dim)\n",
        "        \n",
        "    \n",
        "    def forward(self, inp, hidden_cell):\n",
        "        embedded = self.embedding(inp)\n",
        "        lstm_out, hidden = self.lstm(embedded.view(1,1,-1), hidden_cell)\n",
        "        res = self.out(lstm_out.view(1, -1))\n",
        "        res = fnc.log_softmax(res, dim=1)\n",
        "        \n",
        "        return res, hidden \n",
        "        \n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden=torch.zeros(self.n_layers,1,self.h_dim)\n",
        "        cell = torch.zeros(self.n_layers,1,self.h_dim)\n",
        "        return hidden, cell"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChYfKRC6KYev"
      },
      "source": [
        "def generate(LSTM_model, start='i', max_len=150, num_lines=4, temp=0.8):\r\n",
        "    hidden, cell = LSTM_model.init_hidden()\r\n",
        "    prime_input = phrase_to_tensor([[start]], index_dict)\r\n",
        "    predicted = [start]\r\n",
        "\r\n",
        "    for p in range(len(prime_input)):\r\n",
        "        _, (hidden, cell) = LSTM_model(prime_input[p], (hidden, cell)) \r\n",
        "    input = prime_input[-1]\r\n",
        "    \r\n",
        "    line_count=0\r\n",
        "    for p in range(max_len):\r\n",
        "        if line_count>=num_lines:\r\n",
        "          break\r\n",
        "\r\n",
        "        output, (hidden, cell) = LSTM_model(input, (hidden, cell))\r\n",
        "        \r\n",
        "        output_dist = output.data.view(-1).div(temp).exp()\r\n",
        "        i = int(torch.multinomial(output_dist, 1)[0]) \r\n",
        "        predicted_next = rev_index_dict[i]\r\n",
        "\r\n",
        "        if predicted_next=='endline':\r\n",
        "          line_count= line_count+1\r\n",
        "        \r\n",
        "        predicted.append(predicted_next)\r\n",
        "        input = phrase_to_tensor([[predicted_next]],index_dict)\r\n",
        "\r\n",
        "    return predicted"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsTyR1A50X82"
      },
      "source": [
        "import time, math\r\n",
        "\r\n",
        "def time_since(since):\r\n",
        "    s = time.time() - since\r\n",
        "    m = math.floor(s / 60)\r\n",
        "    s -= m * 60\r\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omh1cVb50f8W"
      },
      "source": [
        "def training_step(LSTM_model, optimizer, input, target, sample_len, criterion):\r\n",
        "    hidden, cell = LSTM_model.init_hidden()\r\n",
        "    LSTM_model.zero_grad()\r\n",
        "    loss = 0\r\n",
        "    for c in range(sample_len):\r\n",
        "        output, (hidden, cell) = LSTM_model(input[c], (hidden, cell))\r\n",
        "        loss = loss + criterion(output, target[c].view(1))\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    return loss.item() /sample_len"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzPlrWUZ1Ig0"
      },
      "source": [
        "#The simplest neural model we try out has a hidden size of 128 and just one lstm layer\r\n",
        "hidden_size = 128\r\n",
        "n_layers = 1\r\n",
        "n_items= len(index_dict)\r\n",
        "\r\n",
        "lr = 0.005\r\n",
        "onelayer_LSTM_model = LSTM(n_items, n_items, hidden_size, n_layers, embedding_dim=100)\r\n",
        "optimizer = torch.optim.Adam(onelayer_LSTM_model.parameters(), lr=lr)\r\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e49lTFSL3kOM"
      },
      "source": [
        "#pickle the object for further training sessions\r\n",
        "pickle.dump(onelayer_LSTM_model, open( \"1lyr_word_level_LSTM.p\", \"wb\" ))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D2DiFcG46As"
      },
      "source": [
        "onelayer_LSTM_model = pickle.load(open( \"lyr_word_level_LSTM.p\", \"rb\" ))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Y8AfIewtRC"
      },
      "source": [
        "#train single layer lstm on 30000 random training verses\r\n",
        "\r\n",
        "def train(model, optimizer, criterion, n_epochs,print_every, plot_every, index_list, return_loss_array):\r\n",
        "  loss_avg=0\r\n",
        "  all_losses=[]\r\n",
        "  start = time.time()\r\n",
        "  for epoch in range(1, n_epochs+1):\r\n",
        "    phrase = random_training_tensor(index_list)\r\n",
        "    #on very rare occasions (1 or two samples) this throws an IndexError.\r\n",
        "    try:\r\n",
        "      loss = training_step(model, optimizer, phrase[0], phrase[1], len(phrase[1]), criterion)\r\n",
        "    except IndexError:\r\n",
        "      print(\"Error: \",phrase)\r\n",
        "    loss_avg += loss\r\n",
        "\r\n",
        "    if epoch % print_every == 0:\r\n",
        "        print('[{} ({} {}%) {:.4f}]'.format(time_since(start), epoch, epoch/n_epochs * 100, loss))\r\n",
        "        print(nice_format(generate(model)), '\\n')\r\n",
        "\r\n",
        "    if epoch % plot_every == 0:\r\n",
        "        all_losses.append(loss_avg/ plot_every)\r\n",
        "        loss_avg = 0\r\n",
        "    \r\n",
        "  if return_loss_array:\r\n",
        "    return all_losses"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkXn7TnW_4ms"
      },
      "source": [
        "def nice_format(output_list):\r\n",
        "        with_linebreaks = [\"\\n\" if x=='endline' else x for x in output_list]\r\n",
        "        return \" \".join(with_linebreaks)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTBEwGrXlIYG"
      },
      "source": [
        "#A word level network with two hidden layers\r\n",
        "hidden_size = 128\r\n",
        "n_layers = 2\r\n",
        "loss_array = []\r\n",
        "n_items= len(index_dict)\r\n",
        "\r\n",
        "lr = 0.005\r\n",
        "twolayer_LSTM_model = LSTM(n_items, n_items, hidden_size, n_layers, embedding_dim=100)\r\n",
        "optimizer = torch.optim.Adam(twolayer_LSTM_model.parameters(), lr=lr)\r\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXWTI2UOoNyD",
        "outputId": "acb07ec3-bb9f-4771-b156-f0a782fbdeaf"
      },
      "source": [
        "loss_array = loss_array +train(twolayer_LSTM_model, optimizer, criterion, 20000, 1000, 10, train_set, return_loss_array=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5m 11s (1000 5.0%) 4.5836]\n",
            "i go to beg \n",
            " catch care of wallet \n",
            " i smoke you in my couch \n",
            " you know i 've been ridin ' on the passin ' eyes \n",
            " \n",
            "\n",
            "[10m 22s (2000 10.0%) 4.6040]\n",
            "i stay away \n",
            " you could go back \n",
            " i would do wo n't know i am the gang \n",
            " and you want it i'ma think there for real \n",
            " \n",
            "\n",
            "[15m 32s (3000 15.0%) 4.5529]\n",
            "i ca n't take a plane \n",
            " broken i am see i 'm ridin ' \n",
            " i cant get this game \n",
            " no less clocks with the sun more real \n",
            " \n",
            "\n",
            "[20m 40s (4000 20.0%) 5.5018]\n",
            "i go to you real time to down \n",
            " i often \n",
            " but a beast 'fore you get like \n",
            " i got nothing straight tryna pull up \n",
            " \n",
            "\n",
            "[25m 49s (5000 25.0%) 3.4650]\n",
            "i 'm like i need to do your name \n",
            " when you with else i earn the power i 'm slapped \n",
            " but i 'm as hell i 'm not a thug up \n",
            " it 's like a shame make a choice \n",
            " \n",
            "\n",
            "[31m 2s (6000 30.0%) 4.4782]\n",
            "i made that i can give a fuck \n",
            " you can not listen \n",
            " hold in my chest \n",
            " because i make a true day \n",
            " \n",
            "\n",
            "[36m 11s (7000 35.0%) 4.7560]\n",
            "i eat stage hard \n",
            " we do n't care the top \n",
            " go in the future \n",
            " why do you stop \n",
            " \n",
            "\n",
            "[41m 24s (8000 40.0%) 4.2493]\n",
            "i 'm talkin ' hop the shit \n",
            " then i 'm in the face with everybody \n",
            " but then the southside come up yeah \n",
            " i got bitch i 'm a the fuck i 'm a man we die \n",
            " \n",
            "\n",
            "[46m 37s (9000 45.0%) 4.6393]\n",
            "i was fuckin ' they beat ' it \n",
            " i 'm gone and you ready to get down \n",
            " i know you got a tree \n",
            " i 'm trying to break it away \n",
            " \n",
            "\n",
            "[51m 50s (10000 50.0%) 4.9526]\n",
            "i 'm on told you that you will \n",
            " i ai n't even even give it \n",
            " and i love the hoes straight for this \n",
            " i 'm in need me \n",
            " \n",
            "\n",
            "[57m 3s (11000 55.00000000000001%) 4.1957]\n",
            "i ai n't coming up your eyes \n",
            " where ya 's that do n't start to slow \n",
            " she ai n't got ta be in the chest two \n",
            " we know your whole hair \n",
            " \n",
            "\n",
            "[62m 13s (12000 60.0%) 4.3331]\n",
            "i 'm skate down \n",
            " i 'm just thats \n",
            " i 'm bout to pay the nigga and i 'm about love \n",
            " i do n't know you want the streets \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOXvj7rwoOzy"
      },
      "source": [
        "#pickle the object for further training sessions\r\n",
        "pickle.dump(twolayer_LSTM_model, open( \"2lyr_word_level_LSTM.p\", \"wb\" ))\r\n",
        "pickle.dump(loss_array, open( \"2lyr_losses.p\", \"wb\" ))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBUfZdo71T6F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}