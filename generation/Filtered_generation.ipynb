{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk import ngrams\n",
    "import torch\n",
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fnc\n",
    "import itertools\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The code for the model classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, embedding_dim=100):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.i_dim= input_dim\n",
    "        self.e_dim= embedding_dim\n",
    "        self.h_dim= hidden_dim\n",
    "        self.o_dim= output_dim\n",
    "        self.n_layers= num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.i_dim, self.e_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.e_dim, hidden_size=self.h_dim, num_layers=self.n_layers)\n",
    "        self.out = nn.Linear(self.h_dim,self.o_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, inp, hidden_cell):\n",
    "        embedded = self.embedding(inp)\n",
    "        lstm_out, hidden = self.lstm(embedded.view(1,1,-1), hidden_cell)\n",
    "        res = self.out(lstm_out.view(1, -1))\n",
    "        res = fnc.log_softmax(res, dim=1)\n",
    "        \n",
    "        return res, hidden \n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden=torch.zeros(self.n_layers,1,self.h_dim)\n",
    "        cell = torch.zeros(self.n_layers,1,self.h_dim)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(LSTM_model, start=['i'], max_len=150, num_lines=4, temp=0.8):\n",
    "    hidden, cell = LSTM_model.init_hidden()\n",
    "    prime_input = phrase_to_tensor([start], index_dict)\n",
    "    predicted = start[:]\n",
    "\n",
    "    for p in range(len(prime_input)):\n",
    "        _, (hidden, cell) = LSTM_model(prime_input[p], (hidden, cell)) \n",
    "    input = prime_input[-1]\n",
    "    \n",
    "    line_count=0\n",
    "    for p in range(max_len):\n",
    "        if line_count>=num_lines:\n",
    "            break\n",
    "        output, (hidden, cell) = LSTM_model(input, (hidden, cell))\n",
    "        \n",
    "        output_dist = output.data.view(-1).div(temp).exp()\n",
    "        i = int(torch.multinomial(output_dist, 1)[0]) \n",
    "        predicted_next = rev_index_dict[i]\n",
    "\n",
    "        if predicted_next=='endline':\n",
    "            line_count= line_count+1\n",
    "        \n",
    "        predicted.append(predicted_next)\n",
    "        input = phrase_to_tensor([[predicted_next]],index_dict)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_format(output_list, meta_list=[]):\n",
    "        no_meta = [x for x in output_list if x not in meta_list]\n",
    "        with_linebreaks = [\"\\n\" if x=='endline' else x for x in no_meta]\n",
    "        return \" \".join(with_linebreaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngram_markov_generator(object):\n",
    "    \n",
    "    def __init__(self, order,  end='nxtsng', endline='endline', meta_list=['nxtvrse','nxtsng']):\n",
    "        self.end = end\n",
    "        self.endline = endline\n",
    "        self.meta_list = meta_list\n",
    "        self.order =order\n",
    "        self.freq_dict = dict()\n",
    "        \n",
    "    def train(self, tknzd_txt_list):\n",
    "        for text in tknzd_txt_list:\n",
    "            grams = list(ngrams(text, self.order+1))\n",
    "            for gram in grams:\n",
    "                self.add_to_dict(gram)\n",
    "            \n",
    "    def add_to_dict(self, gram):\n",
    "        try:\n",
    "            self.freq_dict[gram[:-1]][gram[-1]]+=1\n",
    "        except KeyError:\n",
    "            self.freq_dict[gram[:-1]]= FreqDist([gram[-1]])\n",
    "    \n",
    "    def generate_text(self, start, max_len=20, temp=1):\n",
    "        key = start[-self.order:]\n",
    "        res_sent= start\n",
    "        \n",
    "        for _ in itertools.repeat(None, max_len):\n",
    "            \n",
    "            with_temp = {key: value**(1/temp) for key, value in self.freq_dict[tuple(key)].items()}\n",
    "            dist = nltk.DictionaryProbDist(with_temp,normalize=True)\n",
    "            \n",
    "            nextword = str(dist.generate())\n",
    "            res_sent.append(nextword)\n",
    "            \n",
    "            if nextword==self.end:\n",
    "                break\n",
    "                \n",
    "            key =res_sent[-self.order:]\n",
    "        \n",
    "        return res_sent\n",
    "    \n",
    "    def generate_lines(self, start, num_lines, max_len=200, temp=1):\n",
    "        key = start[-self.order:]\n",
    "        res_sent= start\n",
    "        linecount=0\n",
    "        for x in range(max_len):\n",
    "            \n",
    "            with_temp = {key: value**(1/temp) for key, value in self.freq_dict[tuple(key)].items()}\n",
    "            dist = nltk.DictionaryProbDist(with_temp,normalize=True)\n",
    "            \n",
    "            nextword = str(dist.generate())\n",
    "            \n",
    "            if nextword==self.endline:\n",
    "                linecount = linecount + 1\n",
    "            \n",
    "            if linecount >= num_lines:\n",
    "                break\n",
    "            \n",
    "            if nextword==self.end:\n",
    "                break\n",
    "            \n",
    "            res_sent.append(nextword)   \n",
    "            key =res_sent[-self.order:]\n",
    "        \n",
    "        return res_sent\n",
    "    def nice_format(self, output_list):\n",
    "        no_meta = [x for x in output_list if x not in self.meta_list]\n",
    "        with_linebreaks = [\"\\n\" if x==self.endline else x for x in no_meta]\n",
    "        return \" \".join(with_linebreaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**unpickling data and neural models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHHLA_list = pickle.load(open(\"OHHLAdata_list.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TwoLyrBig = pickle.load(open(\"2lyr_word_level_LSTM(2).p\",\"rb\"))\n",
    "OneLyrBig = pickle.load(open(\"Biglyr_word_level_lstm(1).p\",\"rb\"))\n",
    "TwoLyrSmall = pickle.load(open(\"smallvocab2(1).p\",\"rb\"))\n",
    "OneLyrSmall = pickle.load(open(\"smallvocab(1).p\",\"rb\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training ngram-markov**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_mc = ngram_markov_generator(2)\n",
    "trigram_mc.train(OHHLA_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgram_mc = ngram_markov_generator(3)\n",
    "fgram_mc.train(OHHLA_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtered generation function**  \n",
    "As a proof of concept we implemented a function that uses the classifier as a filter for selecting only the generated lyrics with the best score (probability) according to the classifier. Does not work for neural models yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.24.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = pickle.load(open(\"mnb_classifier.p\",\"rb\"))\n",
    "tfidf_dict = pickle.load(open(\"tfidf_dict.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_generate(generator, start_sequence= [\"nxtvrse\",\"hello\",\"world\"], num_lines=4, max_words=200, selection_size=100, temperature=0.8):\n",
    "    candidates= []\n",
    "    for x in range(selection_size):\n",
    "        candidates.append(generator.nice_format(generator.generate_lines(start_sequence[:], num_lines, max_words, temperature)))\n",
    "    #todo filter for max score candidate\n",
    "    transformed = tfidf_dict.transform(candidates)\n",
    "    \n",
    "    scores = [x[1] for x in classifier.predict_proba(transformed)]\n",
    "    maxscore_indx = scores.index(max(scores))\n",
    "    return candidates[maxscore_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world \n",
      " and when i'm drinkin that goosey witta me brew \n",
      " doin a di realest ting yuh know \n",
      " if you ain't got a grudge i know i took this year\n",
      "hello world \n",
      " cause i ain't sayin' nothin' \n",
      " reflectin' rhymes eternal like your balls and your nigga want beef then goget boy had this shit \n",
      " i ain't talking 'bout\n",
      "hello world \n",
      " of a snake \n",
      " pullin up in the hype \n",
      " they say they a lil nigga with a real nigga\n",
      "hello world how we livin \n",
      " do you want weed holla at ya girl and please tell mi seh slew dem hit dat one yah name!!! cho!!!! \n",
      " tell me what the fuck up the river wit yo body \n",
      " my new honey dew\n",
      "hello world alright \n",
      " do them niggas feind for more \n",
      " you ain't grabbin' the thang \n",
      " when i get uh huh uh huh\n",
      "hello world \n",
      " oops caught me in the back of your friends know i was on a hoe like a boss i'm moving on the mic an bust \n",
      " but i never gave a fuck if you let these niggaz acting like she on my line did i do it for the realest \n",
      " man why me love\n",
      "hello world \n",
      " i ain't livin large checks comin and i smile as i open eyes \n",
      " and have a number one in the kitchen with the fly away quick \n",
      " either i'm finna blow her back to the basics\n",
      "hello world \n",
      " who freaked who bitch i got your back \n",
      " and i ain't got no flavor no sauce niggas lil bitch \n",
      " like i'm supposed to\n",
      "hello world \n",
      " just to make friends with benefits to hit the freeway \n",
      " grab the microphone and keep on movin' i'ma keep the panties \n",
      " then we go now ya gotta suck a dick for the camera\n",
      "hello world \n",
      " you just keep that glock kick like a man \n",
      " d4l i'm ready to ride \n",
      " bitch ain't no comin back\n",
      "hello world \n",
      " can i not mention me master mc no one to be your very last time i hit the hooker hooker hooker \n",
      " hooker for who you with a bottle of dom pop a lotta wack niggas with that nina \n",
      " gotta get my shit\n",
      "hello world \n",
      " i got long bread shawty \n",
      " where the bad the ho's are swingin' off me \n",
      " i ain't gonna bust your whole crew is dirty my nigga\n",
      "hello world \n",
      " blow a square take a ride to the motherfuckin' house \n",
      " bitch i gotta do a little somethin to say you love me instead of steppin wit the drop of a bad bitch \n",
      "\n",
      "hello world \n",
      " to be the niggas who got work to get it mistaken \n",
      " cuz i'm a stay pon toppa tings! diss emanuel mi buss dem head like a cheap car \n",
      " but it's the afterparty we're gonna go back to the beat\n",
      "hello world \n",
      " fuck all these cum rags keep comparing white rappers weren't a cliche \n",
      " so i can spit it like a alkatel \n",
      " dem a talk bout business\n",
      "hello world how we handle our business on the wood weed rocks and gamblers caught up in the game with a fat dick for a different cloth is on my face expression \n",
      " unity suh that haffi in a voodoo \n",
      " stir up the album you try to box i'll beat you down \n",
      " with a black man nigga trynna stay eatin' llike jesus and tech flexing felly fell\n",
      "hello world \n",
      " fuck a pot and let me get 'em \n",
      " and when it's time \n",
      " nuh time fi tek yo self\n",
      "hello world \n",
      " word up \n",
      " roll up a blunt lean on my deck bump bump \n",
      " we got a whole lot of money\n",
      "hello world it's a 30 h you pass the mic smoke blunts out the hood for a beattape \n",
      " i tell 'em what we get to me and i don't know how we live in niggaz moms on crack \n",
      " i just wanna glimpse of truth be told \n",
      " i learned to make the whole world know\n",
      "hello world \n",
      " fuck y'all niggaz i'm chauvinistic \n",
      " i see ya \n",
      " blast 'em do 187\n"
     ]
    }
   ],
   "source": [
    "#print 20 filtered sentences\n",
    "for y in range(20):\n",
    "    print(filtered_generate(trigram_mc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
