{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntJuLRa/ANLP-project-/blob/dev/generation/word_level_LSTM_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ic0Mltqd-Cq",
        "outputId": "405e759e-4db1-4271-b6b2-4d42b2a7ffe0"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import nltk\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fnc\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc736869b58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY-gxXJOd-Dx"
      },
      "source": [
        "OHHLA_data = pickle.load(open( \"OHHLAdata.p\", \"rb\" ))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ujr8tEogfNO"
      },
      "source": [
        "flat_data = [word for song in OHHLA_data for word in song]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1lEAHZgkzDH"
      },
      "source": [
        "freq_dict= nltk.FreqDist(flat_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxY_38Rzo3SH"
      },
      "source": [
        "valid_vocab= [word for word,freq in freq_dict.items() if freq>30]\r\n",
        "invalid_vocab= [word for word,freq in freq_dict.items() if freq<=30]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLG8qoAQfoFw",
        "outputId": "e5a14398-efb5-4e28-ef1a-1a810cba84da"
      },
      "source": [
        "len(valid_vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZnx8lEMoxLf"
      },
      "source": [
        "index_dict = dict()\r\n",
        "for i, x in enumerate(valid_vocab):\r\n",
        "  index_dict[x]=i+1\r\n",
        "\r\n",
        "rev_index_dict = dict([reversed(i) for i in index_dict.items()])\r\n",
        "\r\n",
        "def phrase_to_tensor(phrase, ind_dict):\r\n",
        "  word_list = [word for line in phrase for word in line]\r\n",
        "  tensor = torch.zeros(len(word_list)).long()\r\n",
        "  for i, x in enumerate(word_list):\r\n",
        "    try:\r\n",
        "      tensor[i]=ind_dict[x]\r\n",
        "    except KeyError:\r\n",
        "      tensor[i]=0\r\n",
        "  return tensor"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ2ovWwFjryD"
      },
      "source": [
        "from itertools import groupby\r\n",
        "#We train on sequences of four lines\r\n",
        "verses = [list(x) for y in OHHLA_data for k, x in groupby(y, lambda x: x =='nxtvrse') if not k]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJMjTX3cjHi3"
      },
      "source": [
        "def get_phrases(verse,num_lines=4,endline='endline'):\r\n",
        "  lines = [list(x)+[endline] for k, x in groupby(verse, lambda x: x ==endline) if not k]\r\n",
        "  res=[]\r\n",
        "  for i,x in enumerate (lines[:len(lines)-num_lines+1]):\r\n",
        "    res.append(lines[i:i+num_lines])\r\n",
        "  return res"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo5Ib7zS-X2W"
      },
      "source": [
        "list_of_phrases=[get_phrases(verse) for verse in verses]\r\n",
        "phrases=[x for y in list_of_phrases for x in y]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIETCmYYFwdK"
      },
      "source": [
        "invalid_phrases= []\r\n",
        "for i,phrase in enumerate(phrases):\r\n",
        "  for word in [word for line in phrase for word in line]:\r\n",
        "    if freq_dict[word]<=30:\r\n",
        "      invalid_phrases.append(i)\r\n",
        "      break"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iKbRwyjq7Zk"
      },
      "source": [
        "valid_phrases = list(set(list(range(0,len(phrases)))) - set(invalid_phrases))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iviZ9ZBitu_8"
      },
      "source": [
        "def random_valid_phrase():\r\n",
        "  i= random.choice(valid_phrases)\r\n",
        "  return phrases[i]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaJMSomO1y56"
      },
      "source": [
        "def random_training_set():    \r\n",
        "    x=random_valid_phrase()\r\n",
        "    phrase = phrase_to_tensor(x,index_dict)\r\n",
        "    input = phrase[:-1]\r\n",
        "    target = phrase[1:]\r\n",
        "    return input, target"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNoM3xmed-D6"
      },
      "source": [
        "**LSTM for text generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5cVhVlFd-EC"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, embedding_dim=100):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.i_dim= input_dim\n",
        "        self.e_dim= embedding_dim\n",
        "        self.h_dim= hidden_dim\n",
        "        self.o_dim= output_dim\n",
        "        self.n_layers= num_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.i_dim, self.e_dim)\n",
        "        self.lstm = nn.LSTM(input_size=self.e_dim, hidden_size=self.h_dim, num_layers=self.n_layers)\n",
        "        self.out = nn.Linear(self.h_dim,self.o_dim)\n",
        "        \n",
        "    \n",
        "    def forward(self, inp, hidden_cell):\n",
        "        embedded = self.embedding(inp)\n",
        "        lstm_out, hidden = self.lstm(embedded.view(1,1,-1), hidden_cell)\n",
        "        res = self.out(lstm_out.view(1, -1))\n",
        "        res = fnc.log_softmax(res, dim=1)\n",
        "        \n",
        "        return res, hidden \n",
        "        \n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden=torch.zeros(self.n_layers,1,self.h_dim)\n",
        "        cell = torch.zeros(self.n_layers,1,self.h_dim)\n",
        "        return hidden, cell"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChYfKRC6KYev"
      },
      "source": [
        "def generate(LSTM_model, start='i', max_len=150, num_lines=4, temp=0.8):\r\n",
        "    hidden, cell = LSTM_model.init_hidden()\r\n",
        "    prime_input = phrase_to_tensor([[start]], index_dict)\r\n",
        "    predicted = [start]\r\n",
        "\r\n",
        "    for p in range(len(prime_input)):\r\n",
        "        _, (hidden, cell) = LSTM_model(prime_input[p], (hidden, cell)) \r\n",
        "    input = prime_input[-1]\r\n",
        "    \r\n",
        "    line_count=0\r\n",
        "    for p in range(max_len):\r\n",
        "        if line_count>=num_lines:\r\n",
        "          break\r\n",
        "\r\n",
        "        output, (hidden, cell) = LSTM_model(input, (hidden, cell))\r\n",
        "        \r\n",
        "        output_dist = output.data.view(-1).div(temp).exp()\r\n",
        "        i = int(torch.multinomial(output_dist, 1)[0]) \r\n",
        "        predicted_next = rev_index_dict[i]\r\n",
        "\r\n",
        "        if predicted_next=='endline':\r\n",
        "          line_count= line_count+1\r\n",
        "        \r\n",
        "        predicted.append(predicted_next)\r\n",
        "        input = phrase_to_tensor([[predicted_next]],index_dict)\r\n",
        "\r\n",
        "    return predicted"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsTyR1A50X82"
      },
      "source": [
        "import time, math\r\n",
        "\r\n",
        "def time_since(since):\r\n",
        "    s = time.time() - since\r\n",
        "    m = math.floor(s / 60)\r\n",
        "    s -= m * 60\r\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omh1cVb50f8W"
      },
      "source": [
        "def training_step(LSTM_model, optimizer, input, target, sample_len, criterion):\r\n",
        "    hidden, cell = LSTM_model.init_hidden()\r\n",
        "    LSTM_model.zero_grad()\r\n",
        "    loss = 0\r\n",
        "    for c in range(sample_len):\r\n",
        "        output, (hidden, cell) = LSTM_model(input[c], (hidden, cell))\r\n",
        "        loss = loss + criterion(output, target[c].view(1))\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    return loss.item() /sample_len"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzPlrWUZ1Ig0",
        "outputId": "590f9075-01fd-42bd-fdf7-33ec742dd2f6"
      },
      "source": [
        "n_epochs = 1000\r\n",
        "print_every = 100\r\n",
        "plot_every = 10\r\n",
        "hidden_size = 128\r\n",
        "n_layers = 2\r\n",
        "n_items= len(index_dict)\r\n",
        "\r\n",
        "lr = 0.005\r\n",
        "LSTM_model = LSTM(n_items, n_items, hidden_size, n_layers, embedding_dim=100)\r\n",
        "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=lr)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "all_losses = []\r\n",
        "loss_avg = 0\r\n",
        "\r\n",
        "for epoch in range(1, n_epochs+1):\r\n",
        "    phrase = random_training_set()\r\n",
        "    loss = training_step(LSTM_model, optimizer, phrase[0], phrase[1], len(phrase[1]), criterion)\r\n",
        "    loss_avg += loss\r\n",
        "\r\n",
        "    if epoch % print_every == 0:\r\n",
        "        print('[{} ({} {}%) {:.4f}]'.format(time_since(start), epoch, epoch/n_epochs * 100, loss))\r\n",
        "        print(generate(LSTM_model), '\\n')\r\n",
        "\r\n",
        "    if epoch % plot_every == 0:\r\n",
        "        all_losses.append(loss_avg/ plot_every)\r\n",
        "        loss_avg = 0"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0m 31s (100 10.0%) 5.8028]\n",
            "['i', 'left', 'endline', 'it', 'endline', 'the', 'that', 'kick', 'for', 'but', 'writing', 'endline', \"'\", \"'s\", 'sounds', 'your', 'he', 'woman', 'a', 'the', 'shit', 'endline'] \n",
            "\n",
            "[1m 1s (200 20.0%) 6.0860]\n",
            "['i', 'anybody', 'will', 'and', 'gets', \"'\", 'you', 'endline', 'you', 'your', 'for', 'a', 'off', 'endline', 'on', 'attention', 'with', 'and', 'of', 'kill', 'roll', 'endline', 'they', 'her', 'to', 'endline'] \n",
            "\n",
            "[1m 32s (300 30.0%) 6.5253]\n",
            "['i', \"'s\", 'he', 'with', 'just', 'day', 'your', 'endline', 'ai', 'nigga', 'endline', 'shit', 'me', 'endline', 'if', 'endline'] \n",
            "\n",
            "[2m 4s (400 40.0%) 6.6513]\n",
            "['i', 'you', 'endline', 'there', 'mind', 'the', 'endline', 'nigga', 'still', 'the', 'these', 'endline', \"'s\", 'think', 'your', 'whole', 'endline'] \n",
            "\n",
            "[2m 37s (500 50.0%) 5.8209]\n",
            "['i', 'how', 'her', 'said', 'endline', 'a', 'seas', 'endline', 'for', 'endline', 'i', \"'m\", 'the', 'ground', 'shit', 'endline'] \n",
            "\n",
            "[3m 7s (600 60.0%) 6.4451]\n",
            "['i', 'to', \"'ll\", 'endline', 'to', 'back', 'me', 'endline', 'i', 'when', 'you', 'when', 'i', \"'m\", 'on', 'of', 'by', 'endline', 'she', 'see', 'in', 'endline'] \n",
            "\n",
            "[3m 38s (700 70.0%) 6.2413]\n",
            "['i', \"'ve\", 'the', 'ground', 'my', 'money', 'the', 'spit', 'endline', 'anybody', \"'ll\", 'but', 'do', \"n't\", 'a', 'lesbian', 'keep', 'the', 'endline', 'i', 'seen', 'afraid', 'mary', 'that', 'endline', 'i', 'your', 'go', 'shit', 'of', 'flexing', 'the', 'water', 'my', 'shit', 'endline'] \n",
            "\n",
            "[4m 10s (800 80.0%) 5.3894]\n",
            "['i', 'got', 'them', 'the', 'discover', 'right', 'what', 'i', 'thought', 'on', 'you', 'made', 'with', 'get', 'feel', 'when', 'niggas', 'the', 'sewn', 'endline', 'and', 'a', 'crowd', 'go', 'feeling', 'them', 'who', 'do', \"n't\", 'got', 'it', 'endline', 'and', 'you', 'try', 'them', 'they', 'oh', 'look', 'is', 'what', 'ya', 'fall', 'the', 'way', 'endline', 'cause', 'you', 'could', \"'\", 'that', \"'m\", 'lost', 'endline'] \n",
            "\n",
            "[4m 41s (900 90.0%) 3.9561]\n",
            "['i', 'do', \"n't\", 'had', 'endline', 'made', 'my', 'club', 'this', 'ranks', 'endline', 'nigga', 'i', 'do', \"n't\", 'know', 'a', 'black', 'endline', 'got', 'endline'] \n",
            "\n",
            "[5m 14s (1000 100.0%) 6.0584]\n",
            "['i', 'can', 'believe', 'endline', 'man', 'that', 'me', 'at', 'endline', 'who', 'me', 'endline', 'they', 'life', 'it', 'to', 'lot', 'endline'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e49lTFSL3kOM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Y8AfIewtRC"
      },
      "source": [
        "LSTM_model = LSTM(n_items, n_items, hidden_size, n_layers, embedding_dim=100)\r\n",
        "optimizer = torch.optim.Adam(LSTM_model.parameters(), lr=lr)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "all_losses = []\r\n",
        "loss_avg = 0\r\n",
        "\r\n",
        "for epoch in range(1, n_epochs+1):\r\n",
        "    phrase = random_training_set()\r\n",
        "    loss = training_step(LSTM_model, optimizer, phrase[0], phrase[1], len(phrase[1]), criterion)\r\n",
        "    loss_avg += loss\r\n",
        "\r\n",
        "    if epoch % print_every == 0:\r\n",
        "        print('[{} ({} {}%) {:.4f}]'.format(time_since(start), epoch, epoch/n_epochs * 100, loss))\r\n",
        "        print(generate(LSTM_model), '\\n')\r\n",
        "\r\n",
        "    if epoch % plot_every == 0:\r\n",
        "        all_losses.append(loss_avg/ plot_every)\r\n",
        "        loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}